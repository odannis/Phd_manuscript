@article{ahoModelSelectionEcologists2014,
  title = {Model Selection for Ecologists: The Worldviews of {{AIC}} and {{BIC}}},
  shorttitle = {Model Selection for Ecologists},
  author = {Aho, Ken and Derryberry, DeWayne and Peterson, Teri},
  year = {2014},
  journal = {Ecology},
  volume = {95},
  number = {3},
  eprint = {43495189},
  eprinttype = {jstor},
  pages = {631--636},
  publisher = {Wiley},
  issn = {0012-9658},
  urldate = {2024-09-09}
}

@article{ahoModelSelectionEcologists2014a,
  title = {Model Selection for Ecologists: The Worldviews of {{AIC}} and {{BIC}}},
  shorttitle = {Model Selection for Ecologists},
  author = {Aho, Ken and Derryberry, DeWayne and Peterson, Teri},
  year = {2014},
  journal = {Ecology},
  volume = {95},
  number = {3},
  eprint = {43495189},
  eprinttype = {jstor},
  pages = {631--636},
  publisher = {Wiley},
  issn = {0012-9658},
  urldate = {2024-09-09}
}

@incollection{akaikeInformationTheoryExtension1998,
  title = {Information {{Theory}} and an {{Extension}} of the {{Maximum Likelihood Principle}}},
  booktitle = {Selected {{Papers}} of {{Hirotugu Akaike}}},
  author = {Akaike, Hirotogu},
  editor = {Parzen, Emanuel and Tanabe, Kunio and Kitagawa, Genshiro},
  year = {1998},
  pages = {199--213},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-1-4612-1694-0_15},
  urldate = {2024-09-02},
  isbn = {978-1-4612-7248-9 978-1-4612-1694-0}
}

@article{amatFastAccurateReconstruction2014,
  title = {Fast, Accurate Reconstruction of Cell Lineages from Large-Scale Fluorescence Microscopy Data},
  author = {Amat, Fernando and Lemon, William and Mossing, Daniel P and McDole, Katie and Wan, Yinan and Branson, Kristin and Myers, Eugene W and Keller, Philipp J},
  year = {2014},
  month = sep,
  journal = {Nature Methods},
  volume = {11},
  number = {9},
  pages = {951--958},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.3036},
  urldate = {2024-09-20},
  langid = {english}
}

@article{amiriInferringGeometricalDynamics2024,
  title = {Inferring Geometrical Dynamics of Cell Nucleus Translocation},
  author = {Amiri, Sirine and Zhang, Yirui and Gerardos, Andonis and Sykes, C{\'e}cile and Ronceray, Pierre},
  year = {2024},
  month = oct,
  journal = {Physical Review Research},
  volume = {6},
  number = {4},
  pages = {043030},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.6.043030},
  urldate = {2024-12-19},
  abstract = {The ability of eukaryotic cells to squeeze through constrictions is limited by the stiffness of their large and rigid nucleus. However, migrating cells are often able to overcome this limitation and pass through constrictions much smaller than their nucleus, a mechanism that is not yet understood. Here, we propose a methodological framework to observe, quantify, and model this nuclear translocation phenomenon through a data-driven approach using microfluidic devices where cells migrate through controlled narrow spaces of sizes comparable to the ones encountered in physiological situations. Stochastic force inference is applied to experimental nuclear trajectories and nuclear shape descriptors, resulting in equations that effectively describe the kinematics of this nuclear translocation phenomenon. By employing a model where the channel geometry is an explicit parameter and by training it over experimental data with different sizes of constrictions, we ensure that the resulting equations are predictive. Altogether, the approach developed here paves the way for a mechanistic and quantitative description of dynamical cell complexity during its motility.}
}

@article{andersenModellingHeatDynamics2000,
  title = {Modelling the Heat Dynamics of a Building Using Stochastic Differential Equations},
  author = {Andersen, Klaus Kaae and Madsen, Henrik and Hansen, Lars H.},
  year = {2000},
  month = jan,
  journal = {Energy and Buildings},
  volume = {31},
  number = {1},
  pages = {13--24},
  issn = {03787788},
  doi = {10.1016/S0378-7788(98)00069-3},
  urldate = {2024-09-03},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@book{andersonOptimalFiltering2005,
  title = {Optimal {{Filtering}}},
  author = {Anderson, Brian D. O. and Moore, John B.},
  year = {2005},
  month = jan,
  publisher = {Dover Publications},
  address = {Mineola, NY},
  isbn = {978-0-486-43938-9},
  langid = {english},
  file = {/home/andonis/Zotero/storage/ELR82KGT/Anderson et Moore - 2005 - Optimal Filtering.pdf}
}

@article{baoStochasticPopulationDynamics2012,
  title = {Stochastic Population Dynamics Driven by {{L{\'e}vy}} Noise},
  author = {Bao, Jianhai and Yuan, Chenggui},
  year = {2012},
  month = jul,
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {391},
  number = {2},
  pages = {363--375},
  issn = {0022247X},
  doi = {10.1016/j.jmaa.2012.02.043},
  urldate = {2023-09-05},
  abstract = {This paper considers stochastic population dynamics driven by L{\'e}vy noise. The contributions of this paper lie in that: (a) Using the Khasminskii--Mao theorem, we show that the stochastic differential equation associated with our model has a unique global positive solution; (b) Applying an exponential martingale inequality with jumps, we discuss the asymptotic pathwise estimation of such a model.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/DDQJUV4M/Bao et Yuan - 2012 - Stochastic population dynamics driven by Lévy nois.pdf}
}

@article{bar-sinaiLearningDatadrivenDiscretizations2019,
  title = {Learning Data-Driven Discretizations for Partial Differential Equations},
  author = {{Bar-Sinai}, Yohai and Hoyer, Stephan and Hickey, Jason and Brenner, Michael P.},
  year = {2019},
  month = jul,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {31},
  pages = {15344--15349},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1814058116},
  urldate = {2024-09-12},
  abstract = {The numerical solution of partial differential equations (PDEs) is challenging because of the need to resolve spatiotemporal features over wide length- and timescales. Often, it is computationally intractable to resolve the finest features in the solution. The only recourse is to use approximate coarse-grained representations, which aim to accurately represent long-wavelength dynamics while properly accounting for unresolved small-scale physics. Deriving such coarse-grained equations is notoriously difficult and often ad hoc. Here we introduce data-driven discretization, a method for learning optimized approximations to PDEs based on actual solutions to the known underlying equations. Our approach uses neural networks to estimate spatial derivatives, which are optimized end to end to best satisfy the equations on a low-resolution grid. The resulting numerical methods are remarkably accurate, allowing us to integrate in time a collection of nonlinear equations in 1 spatial dimension at resolutions 4{\texttimes} to 8{\texttimes} coarser than is possible with standard finite-difference methods.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/6DM3LBY7/Bar-Sinai et al. - 2019 - Learning data-driven discretizations for partial differential equations.pdf}
}

@article{barFittingPartialDifferential1999,
  title = {Fitting Partial Differential Equations to Space-Time Dynamics},
  author = {B{\"a}r, Markus and Hegger, Rainer and Kantz, Holger},
  year = {1999},
  month = jan,
  journal = {Physical Review E},
  volume = {59},
  number = {1},
  pages = {337--342},
  issn = {1063-651X, 1095-3787},
  doi = {10.1103/PhysRevE.59.337},
  urldate = {2022-10-25},
  langid = {english},
  file = {/home/andonis/Zotero/storage/EJTC6NVN/Bär et al. - 1999 - Fitting partial differential equations to space-ti.pdf}
}

@article{barrat-charlaixSparseGenerativeModeling2021,
  title = {Sparse Generative Modeling via Parameter Reduction of {{Boltzmann}} Machines: {{Application}} to Protein-Sequence Families},
  shorttitle = {Sparse Generative Modeling via Parameter Reduction of {{Boltzmann}} Machines},
  author = {{Barrat-Charlaix}, Pierre and Muntoni, Anna Paola and Shimagaki, Kai and Weigt, Martin and Zamponi, Francesco},
  year = {2021},
  month = aug,
  journal = {Physical Review. E},
  volume = {104},
  number = {2-1},
  pages = {024407},
  issn = {2470-0053},
  doi = {10.1103/PhysRevE.104.024407},
  abstract = {Boltzmann machines (BMs) are widely used as generative models. For example, pairwise Potts models (PMs), which are instances of the BM class, provide accurate statistical models of families of evolutionarily related protein sequences. Their parameters are the local fields, which describe site-specific patterns of amino acid conservation, and the two-site couplings, which mirror the coevolution between pairs of sites. This coevolution reflects structural and functional constraints acting on protein sequences during evolution. The most conservative choice to describe the coevolution signal is to include all possible two-site couplings into the PM. This choice, typical of what is known as Direct Coupling Analysis, has been successful for predicting residue contacts in the three-dimensional structure, mutational effects, and generating new functional sequences. However, the resulting PM suffers from important overfitting effects: many couplings are small, noisy, and hardly interpretable; the PM is close to a critical point, meaning that it is highly sensitive to small parameter perturbations. In this work, we introduce a general parameter-reduction procedure for BMs, via a controlled iterative decimation of the less statistically significant couplings, identified by an information-based criterion that selects either weak or statistically unsupported couplings. For several protein families, our procedure allows one to remove more than 90\% of the PM couplings, while preserving the predictive and generative properties of the original dense PM, and the resulting model is far away from criticality, hence more robust to noise.},
  langid = {english},
  pmid = {34525554},
  file = {/home/andonis/Zotero/storage/6ENCB7DS/Barrat-Charlaix et al. - 2021 - Sparse generative modeling via parameter reduction of Boltzmann machines Application to protein-seq.pdf}
}

@article{bayramNumericalMethodsSimulation2018,
  title = {Numerical Methods for Simulation of Stochastic Differential Equations},
  author = {Bayram, Mustafa and Partal, Tugcem and Orucova Buyukoz, Gulsen},
  year = {2018},
  month = jan,
  journal = {Advances in Difference Equations},
  volume = {2018},
  number = {1},
  pages = {17},
  issn = {1687-1847},
  doi = {10.1186/s13662-018-1466-5},
  urldate = {2024-02-12},
  abstract = {In this paper we are concerned with numerical methods to solve stochastic differential equations (SDEs), namely the Euler-Maruyama (EM) and Milstein methods. These methods are based on the truncated Ito-Taylor expansion. In our study we deal with a nonlinear SDE. We approximate to numerical solution using Monte Carlo simulation for each method. Also exact solution is obtained from Ito's formula. To show the effectiveness of the numerical methods, approximation solutions are compared with exact solution for different sample paths. And finally the results of numerical experiments are supported with graphs and error tables.},
  keywords = {Euler-Maruyama method,Milstein method,Monte Carlo methods,stochastic differential equations},
  file = {/home/andonis/Zotero/storage/DM7VENJX/Bayram et al. - 2018 - Numerical methods for simulation of stochastic dif.pdf;/home/andonis/Zotero/storage/V326Y8A9/s13662-018-1466-5.html}
}

@article{benarrochMicrobiologistGuideMembrane2020,
  title = {The {{Microbiologist}}'s {{Guide}} to {{Membrane Potential Dynamics}}},
  author = {Benarroch, Jonatan M. and Asally, Munehiro},
  year = {2020},
  month = apr,
  journal = {Trends in Microbiology},
  volume = {28},
  number = {4},
  pages = {304--314},
  publisher = {Elsevier},
  issn = {0966-842X, 1878-4380},
  doi = {10.1016/j.tim.2019.12.008},
  urldate = {2024-07-19},
  langid = {english},
  pmid = {31952908},
  keywords = {antibiotic resistance,bacterial electrophysiology,bioelectricity,biofilms,cell biophysics,membrane potential dynamics},
  file = {/home/andonis/Zotero/storage/RWXZXUMK/Benarroch et Asally - 2020 - The Microbiologist’s Guide to Membrane Potential D.pdf}
}

@article{benmhenniGlobalOptimizationSparse2022,
  title = {Global Optimization for Sparse Solution of Least Squares Problems},
  author = {Ben Mhenni, Ramzi and Bourguignon, S{\'e}bastien and Ninin, Jordan},
  year = {2022},
  month = sep,
  journal = {Optimization Methods and Software},
  volume = {37},
  number = {5},
  pages = {1740--1769},
  issn = {1055-6788, 1029-4937},
  doi = {10.1080/10556788.2021.1977809},
  urldate = {2023-05-22},
  abstract = {Finding solutions to least-squares problems with low cardinality has found many applications, including portfolio optimization, subset selection in statistics, and inverse problems in signal processing. Although most works consider local approaches that scale with high-dimensional problems, some others addressed its global optimization via mixed integer programming (MIP) reformulations. We propose dedicated branch-and-bound methods for the exact resolution of moderate-size, yet difficult, sparse optimization problems, through three possible formulations: cardinalityconstrained and cardinality-penalized least-squares, and cardinality minimization under quadratic constraints. A specific tree exploration strategy is built. Continuous relaxation problems involved at each node are reformulated as 1-norm-based optimization problems, for which a dedicated algorithm is designed. The obtained certified solutions are shown to better estimate sparsity patterns than standard methods on simulated variable selection problems involving highly correlated variables. Problem instances selecting up to 24 components among 100 variables, and up to 15 components among 1 000 variables, can be solved in less than 1 000s. Unguaranteed solutions obtained by limiting the computing time to 1s are also shown to provide competitive estimates. Our algorithms strongly outperform the CPLEX MIP solver as the dimension increases, especially for quadratically-constrained problems. The source codes are made freely available online.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/GZHP4Q29/Ben Mhenni et al. - 2022 - Global optimization for sparse solution of least s.pdf}
}

@article{benmhenniGlobalOptimizationSparse2022a,
  title = {Global Optimization for Sparse Solution of Least Squares Problems},
  author = {Ben Mhenni, Ramzi and Bourguignon, S{\'e}bastien and Ninin, Jordan},
  year = {2022},
  month = sep,
  journal = {Optimization Methods and Software},
  volume = {37},
  number = {5},
  pages = {1740--1769},
  publisher = {Taylor \& Francis},
  issn = {1055-6788},
  doi = {10.1080/10556788.2021.1977809},
  urldate = {2023-06-06},
  abstract = {Finding solutions to least-squares problems with low cardinality has found many applications, including portfolio optimization, subset selection in statistics, and inverse problems in signal processing. Although most works consider local approaches that scale with high-dimensional problems, some others address its global optimization via mixed integer programming (MIP) reformulations. We propose dedicated branch-and-bound methods for the exact resolution of moderate-size, yet difficult, sparse optimization problems, through three possible formulations: cardinality-constrained and cardinality-penalized least-squares, and cardinality minimization under quadratic constraints. A specific tree exploration strategy is built. Continuous relaxation problems involved at each node are reformulated as {$\ell$}1-norm-based optimization problems, for which a dedicated algorithm is designed. The obtained certified solutions are shown to better estimate sparsity patterns than standard methods on simulated variable selection problems involving highly correlated variables. Problem instances selecting up to 24 components among 100 variables, and up to 15 components among 1000 variables, can be solved in less than 1000 s. Unguaranteed solutions obtained by limiting the computing time to 1s are also shown to provide competitive estimates. Our algorithms strongly outperform the CPLEX MIP solver as the dimension increases, especially for quadratically-constrained problems. The source codes are made freely available online.},
  keywords = {branch-and-bound,cardinality constraint,continuous relaxation,homotopy continuation,Sparse approximation,subset selection},
  file = {/home/andonis/Zotero/storage/VLLMWGBD/Ben Mhenni et al. - 2022 - Global optimization for sparse solution of least s.pdf}
}

@article{blumensathIterativeThresholdingSparse2008,
  title = {Iterative {{Thresholding}} for {{Sparse Approximations}}},
  author = {Blumensath, Thomas and Davies, Mike E.},
  year = {2008},
  month = dec,
  journal = {Journal of Fourier Analysis and Applications},
  volume = {14},
  number = {5-6},
  pages = {629--654},
  issn = {1069-5869, 1531-5851},
  doi = {10.1007/s00041-008-9035-z},
  urldate = {2023-05-22},
  abstract = {Sparse signal expansions represent or approximate a signal using a small number of elements from a large collection of elementary waveforms. Finding the optimal sparse expansion is known to be NP hard in general and non-optimal strategies such as Matching Pursuit, Orthogonal Matching Pursuit, Basis Pursuit and Basis Pursuit De-noising are often called upon. These methods show good performance in practical situations, however, they do not operate on the {$\ell$}0 penalised cost functions that are often at the heart of the problem. In this paper we study two iterative algorithms that are minimising the cost functions of interest. Furthermore, each iteration of these strategies has computational complexity similar to a Matching Pursuit iteration, making the methods applicable to many real world problems. However, the optimisation problem is non-convex and the strategies are only guaranteed to find local solutions, so good initialisation becomes paramount. We here study two approaches. The first approach uses the proposed algorithms to refine the solutions found with other methods, replacing the typically used conjugate gradient solver. The second strategy adapts the algorithms and we show on one example that this adaptation can be used to achieve results that lie between those obtained with Matching Pursuit and those found with Orthogonal Matching Pursuit, while retaining the computational complexity of the Matching Pursuit algorithm.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/2VC7NQ9H/Blumensath et Davies - 2008 - Iterative Thresholding for Sparse Approximations.pdf}
}

@article{blumensathIterativeThresholdingSparse2008a,
  title = {Iterative {{Thresholding}} for {{Sparse Approximations}}},
  author = {Blumensath, Thomas and Davies, Mike E.},
  year = {2008},
  month = dec,
  journal = {Journal of Fourier Analysis and Applications},
  volume = {14},
  number = {5},
  pages = {629--654},
  issn = {1531-5851},
  doi = {10.1007/s00041-008-9035-z},
  urldate = {2023-06-06},
  abstract = {Sparse signal expansions represent or approximate a signal using a small number of elements from a large collection of elementary waveforms. Finding the optimal sparse expansion is known to be NP hard in general and non-optimal strategies such as Matching Pursuit, Orthogonal Matching Pursuit, Basis Pursuit and Basis Pursuit De-noising are often called upon. These methods show good performance in practical situations, however, they do not operate on the {$\ell$}0 penalised cost functions that are often at the heart of the problem. In this paper we study two iterative algorithms that are minimising the cost functions of interest. Furthermore, each iteration of these strategies has computational complexity similar to a Matching Pursuit iteration, making the methods applicable to many real world problems. However, the optimisation problem is non-convex and the strategies are only guaranteed to find local solutions, so good initialisation becomes paramount. We here study two approaches. The first approach uses the proposed algorithms to refine the solutions found with other methods, replacing the typically used conjugate gradient solver. The second strategy adapts the algorithms and we show on one example that this adaptation can be used to achieve results that lie between those obtained with Matching Pursuit and those found with Orthogonal Matching Pursuit, while retaining the computational complexity of the Matching Pursuit algorithm.},
  langid = {english},
  keywords = {0 regularisation,15A29,41A46,68W25,68W40,90C27,Iterative thresholding,Sparse approximations,Subset selection},
  file = {/home/andonis/Zotero/storage/F5F84HEU/Blumensath et Davies - 2008 - Iterative Thresholding for Sparse Approximations.pdf}
}

@article{blumensathIterativeThresholdingSparse2008b,
  title = {Iterative {{Thresholding}} for {{Sparse Approximations}}},
  author = {Blumensath, Thomas and Davies, Mike E.},
  year = {2008},
  month = dec,
  journal = {Journal of Fourier Analysis and Applications},
  volume = {14},
  number = {5},
  pages = {629--654},
  issn = {1531-5851},
  doi = {10.1007/s00041-008-9035-z},
  urldate = {2023-06-07},
  abstract = {Sparse signal expansions represent or approximate a signal using a small number of elements from a large collection of elementary waveforms. Finding the optimal sparse expansion is known to be NP hard in general and non-optimal strategies such as Matching Pursuit, Orthogonal Matching Pursuit, Basis Pursuit and Basis Pursuit De-noising are often called upon. These methods show good performance in practical situations, however, they do not operate on the {$\ell$}0 penalised cost functions that are often at the heart of the problem. In this paper we study two iterative algorithms that are minimising the cost functions of interest. Furthermore, each iteration of these strategies has computational complexity similar to a Matching Pursuit iteration, making the methods applicable to many real world problems. However, the optimisation problem is non-convex and the strategies are only guaranteed to find local solutions, so good initialisation becomes paramount. We here study two approaches. The first approach uses the proposed algorithms to refine the solutions found with other methods, replacing the typically used conjugate gradient solver. The second strategy adapts the algorithms and we show on one example that this adaptation can be used to achieve results that lie between those obtained with Matching Pursuit and those found with Orthogonal Matching Pursuit, while retaining the computational complexity of the Matching Pursuit algorithm.},
  langid = {english},
  keywords = {0 regularisation,15A29,41A46,68W25,68W40,90C27,Iterative thresholding,Sparse approximations,Subset selection},
  file = {/home/andonis/Zotero/storage/R57AWJ4S/Blumensath et Davies - 2008 - Iterative Thresholding for Sparse Approximations.pdf}
}

@article{boninsegnaSparseLearningStochastic2018,
  title = {Sparse Learning of Stochastic Dynamical Equations},
  author = {Boninsegna, Lorenzo and N{\"u}ske, Feliks and Clementi, Cecilia},
  year = {2018},
  month = jun,
  journal = {The Journal of Chemical Physics},
  volume = {148},
  number = {24},
  pages = {241723},
  issn = {0021-9606, 1089-7690},
  doi = {10.1063/1.5018409},
  urldate = {2022-10-25},
  langid = {english},
  file = {/home/andonis/Zotero/storage/9NBWTI6J/Boninsegna et al. - 2018 - Sparse learning of stochastic dynamical equations.pdf}
}

@article{boxScienceStatistics1976,
  title = {Science and {{Statistics}}},
  author = {Box, George E. P.},
  year = {1976},
  month = dec,
  journal = {Journal of the American Statistical Association},
  volume = {71},
  number = {356},
  pages = {791--799},
  publisher = {Taylor \& Francis},
  issn = {0162-1459},
  doi = {10.1080/01621459.1976.10480949},
  urldate = {2023-06-23},
  abstract = {Aspects of scientific method are discussed: In particular, its representation as a motivated iteration in which, in succession, practice confronts theory, and theory, practice. Rapid progress requires sufficient flexibility to profit from such confrontations, and the ability to devise parsimonious but effective models, to worry selectively about model inadequacies and to employ mathematics skillfully but appropriately. The development of statistical methods at Rothamsted Experimental Station by Sir Ronald Fisher is used to illustrate these themes.}
}

@article{bricardEmergenceMacroscopicDirected2013,
  title = {Emergence of Macroscopic Directed Motion in Populations of Motile Colloids},
  author = {Bricard, Antoine and Caussin, Jean-Baptiste and Desreumaux, Nicolas and Dauchot, Olivier and Bartolo, Denis},
  year = {2013},
  month = nov,
  journal = {Nature},
  volume = {503},
  number = {7474},
  pages = {95--98},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature12673},
  urldate = {2024-09-19},
  abstract = {Populations of millions of colloidal rolling particles are shown to self-organize to achieve coherent motion; comparison between experiment and theory based on the microscopic interactions between these `rollers' suggests that hydrodynamic interactions promote the emergence of the collective motion.},
  copyright = {2013 Springer Nature Limited},
  langid = {english},
  keywords = {Engineering,Motility,Statistical physics,thermodynamics and nonlinear dynamics},
  file = {/home/andonis/Zotero/storage/VECVE84D/Bricard et al. - 2013 - Emergence of macroscopic directed motion in populations of motile colloids.pdf}
}

@misc{bruckneretal.LearningDynamicsCell,
  title = {Learning the Dynamics of Cell--Cell Interactions in Confined Cell Migration - Www.Pnas.Org/},
  author = {{Br{\"u}ckner et al.}},
  doi = {10.1073/pnas.2016602118},
  urldate = {2022-11-23},
  howpublished = {https://www.pnas.org/doi/10.1073/pnas.2016602118},
  langid = {english},
  file = {/home/andonis/Zotero/storage/XYC7UTDQ/Learning the dynamics of cell–cell interactions in.pdf;/home/andonis/Zotero/storage/6TKLUI26/pnas.html}
}

@article{brucknerInferringDynamicsUnderdamped2020,
  title = {Inferring the {{Dynamics}} of {{Underdamped Stochastic Systems}}},
  author = {Br{\"u}ckner, David B. and Ronceray, Pierre and Broedersz, Chase P.},
  year = {2020},
  month = jul,
  journal = {Physical Review Letters},
  volume = {125},
  number = {5},
  pages = {058103},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.125.058103},
  urldate = {2023-05-16},
  abstract = {Many complex systems, ranging from migrating cells to animal groups, exhibit stochastic dynamics described by the underdamped Langevin equation. Inferring such an equation of motion from experimental data can provide profound insight into the physical laws governing the system. Here, we derive a principled framework to infer the dynamics of underdamped stochastic systems from realistic experimental trajectories, sampled at discrete times and subject to measurement errors. This framework yields an operational method, Underdamped Langevin Inference, which performs well on experimental trajectories of single migrating cells and in complex high-dimensional systems, including flocks with Viscek-like alignment interactions. Our method is robust to experimental measurement errors, and includes a self-consistent estimate of the inference error.},
  file = {/home/andonis/Zotero/storage/JLAAS3PU/Brückner et al. - 2020 - Inferring the Dynamics of Underdamped Stochastic S.pdf;/home/andonis/Zotero/storage/DXUQ9SHK/PhysRevLett.125.html}
}

@article{brucknerLearningDynamicsCell2021,
  title = {Learning the Dynamics of Cell--Cell Interactions in Confined Cell Migration},
  author = {Br{\"u}ckner, David B. and Arlt, Nicolas and Fink, Alexandra and Ronceray, Pierre and R{\"a}dler, Joachim O. and Broedersz, Chase P.},
  year = {2021},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {7},
  pages = {e2016602118},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.2016602118},
  urldate = {2022-11-18},
  abstract = {The migratory dynamics of cells in physiological processes, ranging from wound healing to cancer metastasis, rely on contact-mediated cell--cell interactions. These interactions play a key role in shaping the stochastic trajectories of migrating cells. While data-driven physical formalisms for the stochastic migration dynamics of single cells have been developed, such a framework for the behavioral dynamics of interacting cells still remains elusive. Here, we monitor stochastic cell trajectories in a minimal experimental cell collider: a dumbbell-shaped micropattern on which pairs of cells perform repeated cellular collisions. We observe different characteristic behaviors, including cells reversing, following, and sliding past each other upon collision. Capitalizing on this large experimental dataset of coupled cell trajectories, we infer an interacting stochastic equation of motion that accurately predicts the observed interaction behaviors. Our approach reveals that interacting noncancerous MCF10A cells can be described by repulsion and friction interactions. In contrast, cancerous MDA-MB-231 cells exhibit attraction and antifriction interactions, promoting the predominant relative sliding behavior observed for these cells. Based on these experimentally inferred interactions, we show how this framework may generalize to provide a unifying theoretical description of the diverse cellular interaction behaviors of distinct cell types.},
  file = {/home/andonis/Zotero/storage/R3FCUMDZ/Brückner et al. - 2021 - Learning the dynamics of cell–cell interactions in.pdf}
}

@article{brucknerStochasticNonlinearDynamics2019,
  title = {Stochastic Nonlinear Dynamics of Confined Cell Migration in Two-State Systems},
  author = {Br{\"u}ckner, David B. and Fink, Alexandra and Schreiber, Christoph and R{\"o}ttgermann, Peter J. F. and R{\"a}dler, Joachim O. and Broedersz, Chase P.},
  year = {2019},
  month = jun,
  journal = {Nature Physics},
  volume = {15},
  number = {6},
  pages = {595--601},
  publisher = {Nature Publishing Group},
  issn = {1745-2481},
  doi = {10.1038/s41567-019-0445-4},
  urldate = {2024-02-06},
  abstract = {Migrating cells in physiological processes, including development, homeostasis and cancer, encounter structured environments and are forced to overcome physical obstacles. Yet, the dynamics of confined cell migration remains poorly understood, and thus there is a need to study the complex motility of cells in controlled confining microenvironments. Here, we develop two-state micropatterns, consisting of two adhesive sites connected by a thin constriction, in which migrating cells perform repeated stochastic transitions. This minimal system enables us to obtain a large ensemble of single-cell trajectories. From these trajectories, we infer an equation of cell motion, which decomposes the dynamics into deterministic and stochastic contributions in position--velocity phase space. Our results reveal that cells in two-state micropatterns exhibit intricate nonlinear migratory dynamics, with qualitatively similar features for a cancerous (MDA-MB-231) and a non-cancerous (MCF10A) cell line. In both cases, the cells drive themselves deterministically into the thin constriction; a process that is sped up by noise. Interestingly, however, these two cell lines have distinct deterministic dynamics: MDA-MB-231 cells exhibit a limit cycle, while MCF10A cells show excitable bistable dynamics. Our approach yields a conceptual framework that may be extended to understand cell migration in more complex confining environments.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  langid = {english},
  keywords = {Biological physics,Statistical physics,thermodynamics and nonlinear dynamics}
}

@article{bruntonDiscoveringGoverningEquations2016,
  title = {Discovering Governing Equations from Data by Sparse Identification of Nonlinear Dynamical Systems},
  author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
  year = {2016},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {113},
  number = {15},
  pages = {3932--3937},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1517384113},
  urldate = {2022-11-23},
  abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
  file = {/home/andonis/Zotero/storage/2NCI6N8S/Brunton et al. - Supporting Information for Discovering governing .pdf;/home/andonis/Zotero/storage/KQLN64BH/Brunton et al. - 2016 - Discovering governing equations from data by spars.pdf}
}

@book{burnhamModelSelectionMultimodel2010,
  title = {Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach},
  shorttitle = {Model Selection and Multimodel Inference},
  author = {Burnham, Kenneth P. and Anderson, David Ray and Anderson, David Raymond},
  year = {2010},
  edition = {2. ed., [4. printing]},
  publisher = {Springer},
  address = {New York, NY},
  isbn = {978-0-387-95364-9 978-1-4419-2973-0},
  langid = {english},
  file = {/home/andonis/Zotero/storage/PNBJ8TVS/Burnham et al. - 2010 - Model selection and multimodel inference a practi.pdf}
}

@article{callahamNonlinearStochasticModelling2021,
  title = {Nonlinear Stochastic Modelling with {{Langevin}} Regression},
  author = {Callaham, J. L. and Loiseau, J.-C. and Rigas, G. and Brunton, S. L.},
  year = {2021},
  month = jun,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {477},
  number = {2250},
  pages = {20210092},
  publisher = {Royal Society},
  doi = {10.1098/rspa.2021.0092},
  urldate = {2023-10-02},
  abstract = {Many physical systems characterized by nonlinear multiscale interactions can be modelled by treating unresolved degrees of freedom as random fluctuations. However, even when the microscopic governing equations and qualitative macroscopic behaviour are known, it is often difficult to derive a stochastic model that is consistent with observations. This is especially true for systems such as turbulence where the perturbations do not behave like Gaussian white noise, introducing non-Markovian behaviour to the dynamics. We address these challenges with a framework for identifying interpretable stochastic nonlinear dynamics from experimental data, using forward and adjoint Fokker--Planck equations to enforce statistical consistency. If the form of the Langevin equation is unknown, a simple sparsifying procedure can provide an appropriate functional form. We demonstrate that this method can learn stochastic models in two artificial examples: recovering a nonlinear Langevin equation forced by coloured noise and approximating the second-order dynamics of a particle in a double-well potential with the corresponding first-order bifurcation normal form. Finally, we apply Langevin regression to experimental measurements of a turbulent bluff body wake and show that the statistical behaviour of the centre of pressure can be described by the dynamics of the corresponding laminar flow driven by nonlinear state-dependent noise.},
  keywords = {data-driven modelling,Fokker-Planck equation,Langevin equation,sparse regression,stochastic modelling,system identification},
  file = {/home/andonis/Zotero/storage/2MLG3NC9/Callaham et al. - 2021 - Nonlinear stochastic modelling with Langevin regre.pdf}
}

@article{candesEnhancingSparsityReweighted2008,
  title = {Enhancing {{Sparsity}} by {{Reweighted}} {$\ell$} 1 {{Minimization}}},
  author = {Cand{\`e}s, Emmanuel J. and Wakin, Michael B. and Boyd, Stephen P.},
  year = {2008},
  month = dec,
  journal = {Journal of Fourier Analysis and Applications},
  volume = {14},
  number = {5-6},
  pages = {877--905},
  issn = {1069-5869, 1531-5851},
  doi = {10.1007/s00041-008-9045-x},
  urldate = {2023-05-22},
  abstract = {It is now well understood that (1) it is possible to reconstruct sparse signals exactly from what appear to be highly incomplete sets of linear measurements and (2) that this can be done by constrained 1 minimization. In this paper, we study a novel method for sparse signal recovery that in many situations outperforms 1 minimization in the sense that substantially fewer measurements are needed for exact recovery. The algorithm consists of solving a sequence of weighted 1-minimization problems where the weights used for the next iteration are computed from the value of the current solution. We present a series of experiments demonstrating the remarkable performance and broad applicability of this algorithm in the areas of sparse signal recovery, statistical estimation, error correction and image processing. Interestingly, superior gains are also achieved when our method is applied to recover signals with assumed near-sparsity in overcomplete representations---not by reweighting the 1 norm of the coefficient sequence as is common, but by reweighting the 1 norm of the transformed object. An immediate consequence is the possibility of highly efficient data acquisition protocols by improving on a technique known as Compressive Sensing.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/X8F9ECZP/Candès et al. - 2008 - Enhancing Sparsity by Reweighted ℓ 1 Minimization.pdf}
}

@article{casadiegoModelfreeInferenceDirect2017,
  title = {Model-Free Inference of Direct Network Interactions from Nonlinear Collective Dynamics},
  author = {Casadiego, Jose and Nitzan, Mor and Hallerberg, Sarah and Timme, Marc},
  year = {2017},
  month = dec,
  journal = {Nature Communications},
  volume = {8},
  number = {1},
  pages = {2192},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-017-02288-4},
  urldate = {2023-10-23},
  abstract = {The topology of interactions in network dynamical systems fundamentally underlies their function. Accelerating technological progress creates massively available data about collective nonlinear dynamics in physical, biological, and technological systems. Detecting direct interaction patterns from those dynamics still constitutes a major open problem. In particular, current nonlinear dynamics approaches mostly require to know a priori a model of the (often high dimensional) system dynamics. Here we develop a model-independent framework for inferring direct interactions solely from recording the nonlinear collective dynamics generated. Introducing an explicit dependency matrix in combination with a block-orthogonal regression algorithm, the approach works reliably across many dynamical regimes, including transient dynamics toward steady states, periodic and non-periodic dynamics, and chaos. Together with its capabilities to reveal network (two point) as well as hypernetwork (e.g., three point) interactions, this framework may thus open up nonlinear dynamics options of inferring direct interaction patterns across systems where no model is known.},
  copyright = {2017 The Author(s)},
  langid = {english},
  keywords = {Complex networks,Machine learning,Network topology,Nonlinear phenomena},
  file = {/home/andonis/Zotero/storage/ZMCWC8AA/Casadiego et al. - 2017 - Model-free inference of direct network interaction.pdf}
}

@article{cavanaughAkaikeInformationCriterion2019,
  title = {The {{Akaike}} Information Criterion: {{Background}}, Derivation, Properties, Application, Interpretation, and Refinements},
  shorttitle = {The {{Akaike}} Information Criterion},
  author = {Cavanaugh, Joseph E. and Neath, Andrew A.},
  year = {2019},
  month = may,
  journal = {WIREs Computational Statistics},
  volume = {11},
  number = {3},
  pages = {e1460},
  issn = {1939-5108, 1939-0068},
  doi = {10.1002/wics.1460},
  urldate = {2024-02-01},
  abstract = {The Akaike information criterion (AIC) is one of the most ubiquitous tools in statistical modeling. The first model selection criterion to gain widespread acceptance, AIC was introduced in 1973 by Hirotugu Akaike as an extension to the maximum likelihood principle. Maximum likelihood is conventionally applied to estimate the parameters of a model once the structure and dimension of the model have been formulated. Akaike's seminal idea was to combine into a single procedure the process of estimation with structural and dimensional determination. This article reviews the conceptual and theoretical foundations for AIC, discusses its properties and its predictive interpretation, and provides a synopsis of important practical issues pertinent to its application. Comparisons and delineations are drawn between AIC and its primary competitor, the Bayesian information criterion (BIC). In addition, the article covers refinements of AIC for settings where the asymptotic conditions and model specification assumptions that underlie the justification of AIC may be violated.                            This article is categorized under:                                                   Software for Computational Statistics {$>$} Artificial Intelligence and Expert Systems                                                     Statistical Models {$>$} Model Selection                                                     Statistical and Graphical Methods of Data Analysis {$>$} Modeling Methods and Algorithms                                                     Statistical and Graphical Methods of Data Analysis {$>$} Information Theoretic Methods},
  langid = {english},
  file = {/home/andonis/Zotero/storage/YB8VTVWL/Cavanaugh et Neath - 2019 - The Akaike information criterion Background, deri.pdf}
}

@article{championUnifiedSparseOptimization2020,
  title = {A {{Unified Sparse Optimization Framework}} to {{Learn Parsimonious Physics-Informed Models From Data}}},
  author = {Champion, Kathleen and Zheng, Peng and Aravkin, Aleksandr Y. and Brunton, Steven L. and Kutz, J. Nathan},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {169259--169271},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.3023625},
  abstract = {Machine learning (ML) is redefining what is possible in data-intensive fields of science and engineering. However, applying ML to problems in the physical sciences comes with a unique set of challenges: scientists want physically interpretable models that can (i) generalize to predict previously unobserved behaviors, (ii) provide effective forecasting predictions (extrapolation), and (iii) be certifiable. Autonomous systems will necessarily interact with changing and uncertain environments, motivating the need for models that can accurately extrapolate based on physical principles (e.g. Newton's universal second law for classical mechanics, F = ma). Standard ML approaches have shown impressive performance for predicting dynamics in an interpolatory regime, but the resulting models often lack interpretability and fail to generalize. We build on a sparse regression framework that discovers governing dynamical systems models from data, selecting relevant terms in the dynamics from a library of possible functions. Our critically enabling innovation introduces a relaxed version of a sparse optimization framework that allows the use of non-convex sparsity promoting regularization functions and addresses three open challenges in scientific problems and data sets: (i) robust handling of outliers and corrupt data within noisy sensor measurements, (ii) parametric dependencies in candidate library functions, and (iii) the imposition of physical constraints. By explicitly addressing these open challenges, the integrated and unified algorithm developed provides a significant advancement over current state-of-the-art sparse model discovery methods. We show that the approach discovers parsimonious dynamical models on several example systems. This flexible approach can be tailored to the unique challenges associated with a wide range of applications and data sets, providing a powerful ML-based framework for learning governing models for physical systems from data.},
  keywords = {Data models,Libraries,Mathematical model,nonconvex optimization,Optimization,outlier removal,Robustness,Sparse regression,Standards,systems identification,Technological innovation},
  file = {/home/andonis/Zotero/storage/7HWGBXJW/Champion et al. - 2020 - A Unified Sparse Optimization Framework to Learn P.pdf;/home/andonis/Zotero/storage/T73IYR8X/stamp.html}
}

@article{chartrandNumericalDifferentiationNoisy2011,
  title = {Numerical {{Differentiation}} of {{Noisy}}, {{Nonsmooth Data}}},
  author = {Chartrand, Rick},
  year = {2011},
  month = may,
  journal = {ISRN Applied Mathematics},
  volume = {2011},
  pages = {1--11},
  issn = {2090-5564, 2090-5572},
  doi = {10.5402/2011/164564},
  urldate = {2022-11-23},
  abstract = {We consider the problem of differentiating a function specified by noisy data. Regularizing the differentiation process avoids the noise amplification of finite-difference methods. We use total-variation regularization, which allows for discontinuous solutions. The resulting simple algorithm accurately differentiates noisy functions, including those which have a discontinuous derivative.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/6TJRD8SA/Chartrand - 2011 - Numerical Differentiation of Noisy, Nonsmooth Data.pdf}
}

@article{chenAutomatedDiscoveryFundamental2022,
  title = {Automated Discovery of Fundamental Variables Hidden in Experimental Data},
  author = {Chen, Boyuan and Huang, Kuang and Raghupathi, Sunand and Chandratreya, Ishaan and Du, Qiang and Lipson, Hod},
  year = {2022},
  month = jul,
  journal = {Nature Computational Science},
  volume = {2},
  number = {7},
  pages = {433--442},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00281-6},
  urldate = {2023-10-10},
  abstract = {All physical laws are described as mathematical relationships between state variables. These variables give a complete and non-redundant description of the relevant system. However, despite the prevalence of computing power and artificial intelligence, the process of identifying the hidden state variables themselves has resisted automation. Most data-driven methods for modelling physical phenomena still rely on the assumption that the relevant state variables are already known. A longstanding question is whether it is possible to identify state variables from only high-dimensional observational data. Here we propose a principle for determining how many state variables an observed system is likely to have, and what these variables might be. We demonstrate the effectiveness of this approach using video recordings of a variety of physical dynamical systems, ranging from elastic double pendulums to fire flames. Without any prior knowledge of the underlying physics, our algorithm discovers the intrinsic dimension of the observed dynamics and identifies candidate sets of state variables.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Applied physics,Computational science,Mechanical engineering}
}

@article{chenAutomatedDiscoveryFundamental2022a,
  title = {Automated Discovery of Fundamental Variables Hidden in Experimental Data},
  author = {Chen, Boyuan and Huang, Kuang and Raghupathi, Sunand and Chandratreya, Ishaan and Du, Qiang and Lipson, Hod},
  year = {2022},
  month = jul,
  journal = {Nature Computational Science},
  volume = {2},
  number = {7},
  pages = {433--442},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00281-6},
  urldate = {2023-10-10},
  abstract = {All physical laws are described as mathematical relationships between state variables. These variables give a complete and non-redundant description of the relevant system. However, despite the prevalence of computing power and artificial intelligence, the process of identifying the hidden state variables themselves has resisted automation. Most data-driven methods for modelling physical phenomena still rely on the assumption that the relevant state variables are already known. A longstanding question is whether it is possible to identify state variables from only high-dimensional observational data. Here we propose a principle for determining how many state variables an observed system is likely to have, and what these variables might be. We demonstrate the effectiveness of this approach using video recordings of a variety of physical dynamical systems, ranging from elastic double pendulums to fire flames. Without any prior knowledge of the underlying physics, our algorithm discovers the intrinsic dimension of the observed dynamics and identifies candidate sets of state variables.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Applied physics,Computational science,Mechanical engineering}
}

@misc{chenDiscoveringStateVariables2021,
  title = {Discovering {{State Variables Hidden}} in {{Experimental Data}}},
  author = {Chen, Boyuan and Huang, Kuang and Raghupathi, Sunand and Chandratreya, Ishaan and Du, Qiang and Lipson, Hod},
  year = {2021},
  month = dec,
  number = {arXiv:2112.10755},
  eprint = {2112.10755},
  primaryclass = {physics},
  publisher = {arXiv},
  urldate = {2023-10-10},
  abstract = {All physical laws are described as relationships between state variables that give a complete and non-redundant description of the relevant system dynamics. However, despite the prevalence of computing power and AI, the process of identifying the hidden state variables themselves has resisted automation. Most data-driven methods for modeling physical phenomena still assume that observed data streams already correspond to relevant state variables. A key challenge is to identify the possible sets of state variables from scratch, given only high-dimensional observational data. Here we propose a new principle for determining how many state variables an observed system is likely to have, and what these variables might be, directly from video streams. We demonstrate the effectiveness of this approach using video recordings of a variety of physical dynamical systems, ranging from elastic double pendulums to fire flames. Without any prior knowledge of the underlying physics, our algorithm discovers the intrinsic dimension of the observed dynamics and identifies candidate sets of state variables. We suggest that this approach could help catalyze the understanding, prediction and control of increasingly complex systems. Project website is at: https://www.cs.columbia.edu/{\textasciitilde}bchen/neural-state-variables},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Dynamical Systems,Physics - Applied Physics},
  file = {/home/andonis/Zotero/storage/PKNQXYEN/Chen et al. - 2021 - Discovering State Variables Hidden in Experimental.pdf}
}

@article{chenLecture7Model,
  title = {Lecture 7: {{Model Selection}} and {{Prediction}}},
  author = {Chen, Yen-Chi},
  langid = {english},
  file = {/home/andonis/Zotero/storage/FVLTKTJW/Chen - Lecture 7 Model Selection and Prediction.pdf}
}

@article{chenNeuralOrdinaryDifferential,
  title = {Neural {{Ordinary Differential Equations}}},
  author = {Chen, Tian Qi and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David K},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/L5PD2KGH/Chen et al. - Neural Ordinary Differential Equations.pdf}
}

@article{chenouardObjectiveComparisonParticle2014,
  title = {Objective Comparison of Particle Tracking Methods},
  author = {Chenouard, Nicolas and Smal, Ihor and {de Chaumont}, Fabrice and Ma{\v s}ka, Martin and Sbalzarini, Ivo F. and Gong, Yuanhao and Cardinale, Janick and Carthel, Craig and Coraluppi, Stefano and Winter, Mark and Cohen, Andrew R. and Godinez, William J. and Rohr, Karl and Kalaidzidis, Yannis and Liang, Liang and Duncan, James and Shen, Hongying and Xu, Yingke and Magnusson, Klas E. G. and Jald{\'e}n, Joakim and Blau, Helen M. and {Paul-Gilloteaux}, Perrine and Roudot, Philippe and Kervrann, Charles and Waharte, Fran{\c c}ois and Tinevez, Jean-Yves and Shorte, Spencer L. and Willemse, Joost and Celler, Katherine and {van Wezel}, Gilles P. and Dan, Han-Wei and Tsai, Yuh-Show and {de Sol{\'o}rzano}, Carlos Ortiz and {Olivo-Marin}, Jean-Christophe and Meijering, Erik},
  year = {2014},
  month = mar,
  journal = {Nature Methods},
  volume = {11},
  number = {3},
  pages = {281--289},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/nmeth.2808},
  urldate = {2024-09-20},
  abstract = {The first community competition designed to objectively compare the performance of particle tracking algorithms provides valuable practical information for both users and developers.},
  copyright = {2013 The Author(s)},
  langid = {english},
  keywords = {Fluorescence imaging,Image processing,Microscopy},
  file = {/home/andonis/Zotero/storage/FHCIS96T/Chenouard et al. - 2014 - Objective comparison of particle tracking methods.pdf}
}

@article{courseStateEstimationPhysical2023,
  title = {State Estimation of a Physical System with Unknown Governing Equations},
  author = {Course, Kevin and Nair, Prasanth B.},
  year = {2023},
  month = oct,
  journal = {Nature},
  volume = {622},
  number = {7982},
  pages = {261--267},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/s41586-023-06574-8},
  urldate = {2024-06-17},
  abstract = {State estimation is concerned with reconciling noisy observations of a physical system with the mathematical model believed to predict its behaviour for the purpose of inferring unmeasurable states and denoising measurable ones1,2. Traditional state-estimation techniques rely on strong assumptions about the form of uncertainty in mathematical models, typically that it manifests as an additive stochastic perturbation or is parametric in nature3. Here we present a reparametrization trick for stochastic variational inference with Markov Gaussian processes that enables an approximate Bayesian approach for state estimation in which the equations governing how the system evolves over time are partially or completely unknown. In contrast to classical state-estimation techniques, our method learns the missing terms in the mathematical model and a state estimate simultaneously from an approximate Bayesian perspective. This development enables the application of state-estimation methods to problems that have so far proved~to be beyond reach. Finally, although we focus on state estimation, the advancements to stochastic variational inference made here are applicable to a broader class of problems in machine learning.},
  copyright = {2023 The Author(s)},
  langid = {english},
  keywords = {Engineering,Mathematics and computing},
  file = {/home/andonis/Zotero/storage/4Y6AZXVG/Course et Nair - 2023 - State estimation of a physical system with unknown.pdf}
}

@article{coverELEMENTSINFORMATIONTHEORY,
  title = {{{ELEMENTS OF INFORMATION THEORY}}},
  author = {Cover, Thomas M and Thomas, Joy A},
  langid = {english},
  file = {/home/andonis/Zotero/storage/IQIW7EPR/Cover et Thomas - ELEMENTS OF INFORMATION THEORY.pdf}
}

@misc{cranmerDiscoveringSymbolicModels2020,
  title = {Discovering {{Symbolic Models}} from {{Deep Learning}} with {{Inductive Biases}}},
  author = {Cranmer, Miles and {Sanchez-Gonzalez}, Alvaro and Battaglia, Peter and Xu, Rui and Cranmer, Kyle and Spergel, David and Ho, Shirley},
  year = {2020},
  month = nov,
  number = {arXiv:2006.11287},
  eprint = {2006.11287},
  primaryclass = {astro-ph, physics:physics, stat},
  publisher = {arXiv},
  urldate = {2023-10-12},
  abstract = {We develop a general approach to distill symbolic representations of a learned deep model by introducing strong inductive biases. We focus on Graph Neural Networks (GNNs). The technique works as follows: we first encourage sparse latent representations when we train a GNN in a supervised setting, then we apply symbolic regression to components of the learned model to extract explicit physical relations. We find the correct known equations, including force laws and Hamiltonians, can be extracted from the neural network. We then apply our method to a non-trivial cosmology example---a detailed dark matter simulation---and discover a new analytic formula which can predict the concentration of dark matter from the mass distribution of nearby cosmic structures. The symbolic expressions extracted from the GNN using our technique also generalized to out-of-distributiondata better than the GNN itself. Our approach offers alternative directions for interpreting neural networks and discovering novel physical principles from the representations they learn.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics,Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,Physics - Computational Physics,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/6DA57W2R/Cranmer et al. - 2020 - Discovering Symbolic Models from Deep Learning wit.pdf}
}

@misc{cranmerInterpretableMachineLearning2023,
  title = {Interpretable {{Machine Learning}} for {{Science}} with {{PySR}} and {{SymbolicRegression}}.Jl},
  author = {Cranmer, Miles},
  year = {2023},
  month = may,
  journal = {arXiv.org},
  urldate = {2023-10-10},
  abstract = {PySR is an open-source library for practical symbolic regression, a type of machine learning which aims to discover human-interpretable symbolic models. PySR was developed to democratize and popularize symbolic regression for the sciences, and is built on a high-performance distributed back-end, a flexible search algorithm, and interfaces with several deep learning packages. PySR's internal search algorithm is a multi-population evolutionary algorithm, which consists of a unique evolve-simplify-optimize loop, designed for optimization of unknown scalar constants in newly-discovered empirical expressions. PySR's backend is the extremely optimized Julia library SymbolicRegression.jl, which can be used directly from Julia. It is capable of fusing user-defined operators into SIMD kernels at runtime, performing automatic differentiation, and distributing populations of expressions to thousands of cores across a cluster. In describing this software, we also introduce a new benchmark, "EmpiricalBench," to quantify the applicability of symbolic regression algorithms in science. This benchmark measures recovery of historical empirical equations from original and synthetic datasets.},
  howpublished = {https://arxiv.org/abs/2305.01582v3},
  langid = {english},
  file = {/home/andonis/Zotero/storage/EFK94FRN/Cranmer - 2023 - Interpretable Machine Learning for Science with Py.pdf}
}

@misc{cranmerInterpretableMachineLearning2023a,
  title = {Interpretable {{Machine Learning}} for {{Science}} with {{PySR}} and {{SymbolicRegression}}.Jl},
  author = {Cranmer, Miles},
  year = {2023},
  month = may,
  number = {arXiv:2305.01582},
  eprint = {2305.01582},
  primaryclass = {astro-ph, physics:physics},
  publisher = {arXiv},
  urldate = {2023-10-10},
  abstract = {PySR is an open-source library for practical symbolic regression, a type of machine learning which aims to discover human-interpretable symbolic models. PySR was developed to democratize and popularize symbolic regression for the sciences, and is built on a high-performance distributed back-end, a flexible search algorithm, and interfaces with several deep learning packages. PySR's internal search algorithm is a multi-population evolutionary algorithm, which consists of a unique evolve-simplify-optimize loop, designed for optimization of unknown scalar constants in newly-discovered empirical expressions. PySR's backend is the extremely optimized Julia library SymbolicRegression.jl, which can be used directly from Julia. It is capable of fusing user-defined operators into SIMD kernels at runtime, performing automatic differentiation, and distributing populations of expressions to thousands of cores across a cluster. In describing this software, we also introduce a new benchmark, "EmpiricalBench," to quantify the applicability of symbolic regression algorithms in science. This benchmark measures recovery of historical empirical equations from original and synthetic datasets.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Symbolic Computation,Physics - Data Analysis Statistics and Probability},
  file = {/home/andonis/Zotero/storage/K4EQESG8/Cranmer - 2023 - Interpretable Machine Learning for Science with Py.pdf}
}

@misc{CVAndonisSkill,
  title = {{{CV Andonis Skill}} Based Hellowatt},
  urldate = {2024-06-14},
  abstract = {An online LaTeX editor that's easy to use. No installation, real-time collaboration, version control, hundreds of LaTeX templates, and more.},
  howpublished = {https://www.overleaf.com/project/6666baf5eb15643c71860ad9},
  langid = {english},
  file = {/home/andonis/Zotero/storage/48YGNSY5/6666baf5eb15643c71860ad9.html}
}

@article{danielsAutomatedAdaptiveInference2015,
  title = {Automated Adaptive Inference of Phenomenological Dynamical Models},
  author = {Daniels, Bryan C. and Nemenman, Ilya},
  year = {2015},
  month = aug,
  journal = {Nature Communications},
  volume = {6},
  number = {1},
  pages = {8133},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/ncomms9133},
  urldate = {2023-09-27},
  abstract = {Dynamics of complex systems is often driven by large and intricate networks of microscopic interactions, whose sheer size obfuscates understanding. With limited experimental data, many parameters of such dynamics are unknown, and thus detailed, mechanistic models risk overfitting and making faulty predictions. At the other extreme, simple ad hoc models often miss defining features of the underlying systems. Here we develop an approach that instead constructs phenomenological, coarse-grained models of network dynamics that automatically adapt their complexity to the available data. Such adaptive models produce accurate predictions even when microscopic details are unknown. The approach is computationally tractable, even for a relatively large number of dynamical variables. Using simulated data, it correctly infers the phase space structure for planetary motion, avoids overfitting in a biological signalling system and produces accurate predictions for yeast glycolysis with tens of data points and over half of the interacting species unobserved.},
  copyright = {2015 The Author(s)},
  langid = {english},
  keywords = {Biophysics,Theoretical physics},
  file = {/home/andonis/Zotero/storage/95TI5K6J/Daniels et Nemenman - 2015 - Automated adaptive inference of phenomenological d.pdf;/home/andonis/Zotero/storage/QGCXRSG9/41467_2015_BFncomms9133_MOESM1115_ESM.pdf}
}

@misc{dawPhysicsguidedNeuralNetworks2021,
  title = {Physics-Guided {{Neural Networks}} ({{PGNN}}): {{An Application}} in {{Lake Temperature Modeling}}},
  shorttitle = {Physics-Guided {{Neural Networks}} ({{PGNN}})},
  author = {Daw, Arka and Karpatne, Anuj and Watkins, William and Read, Jordan and Kumar, Vipin},
  year = {2021},
  month = sep,
  number = {arXiv:1710.11431},
  eprint = {1710.11431},
  primaryclass = {physics, stat},
  publisher = {arXiv},
  urldate = {2022-11-07},
  abstract = {This paper introduces a framework for combining scientific knowledge of physics-based models with neural networks to advance scientific discovery. This framework, termed physics-guided neural networks (PGNN), leverages the output of physics-based model simulations along with observational features in a hybrid modeling setup to generate predictions using a neural network architecture. Further, this framework uses physics-based loss functions in the learning objective of neural networks to ensure that the model predictions not only show lower errors on the training set but are also scientifically consistent with the known physics on the unlabeled set. We illustrate the effectiveness of PGNN for the problem of lake temperature modeling, where physical relationships between the temperature, density, and depth of water are used to design a physics-based loss function. By using scientific knowledge to guide the construction and learning of neural networks, we are able to show that the proposed framework ensures better generalizability as well as scientific consistency of results. All the code and datasets used in this study have been made available on this link {\textbackslash}url\{https://github.com/arkadaw9/PGNN\}.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Physics - Data Analysis Statistics and Probability,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/7NW3A7DM/Daw et al. - 2021 - Physics-guided Neural Networks (PGNN) An Applicat.pdf}
}

@inproceedings{dawPIDGANGANFramework2021,
  title = {{{PID-GAN}}: {{A GAN Framework}} Based on a {{Physics-informed Discriminator}} for {{Uncertainty Quantification}} with {{Physics}}},
  shorttitle = {{{PID-GAN}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Daw, Arka and Maruf, M. and Karpatne, Anuj},
  year = {2021},
  month = aug,
  eprint = {2106.02993},
  primaryclass = {cs, stat},
  pages = {237--247},
  doi = {10.1145/3447548.3467449},
  urldate = {2022-11-23},
  abstract = {As applications of deep learning (DL) continue to seep into critical scientific use-cases, the importance of performing uncertainty quantification (UQ) with DL has become more pressing than ever before. In scientific applications, it is also important to inform the learning of DL models with knowledge of physics of the problem to produce physically consistent and generalized solutions. This is referred to as the emerging field of physics-informed deep learning (PIDL). We consider the problem of developing PIDL formulations that can also perform UQ. To this end, we propose a novel physics-informed GAN architecture, termed PID-GAN, where the knowledge of physics is used to inform the learning of both the generator and discriminator models, making ample use of unlabeled data instances. We show that our proposed PID-GAN framework does not suffer from imbalance of generator gradients from multiple loss terms as compared to state-of-the-art. We also empirically demonstrate the efficacy of our proposed framework on a variety of case studies involving benchmark physics-based PDEs as well as imperfect physics. All the code and datasets used in this study have been made available on this link : https://github.com/arkadaw9/PID-GAN.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/TB8BDQU4/Daw et al. - 2021 - PID-GAN A GAN Framework based on a Physics-inform.pdf;/home/andonis/Zotero/storage/CP6MTFT3/2106.html}
}

@article{desouza-guerreiroMembraneTargetedAzobenzene2023,
  title = {Membrane {{Targeted Azobenzene Drives Optical Modulation}} of {{Bacterial Membrane Potential}}},
  author = {{de Souza-Guerreiro}, Tailise Carolina and Bondelli, Gaia and Grobas, Iago and Donini, Stefano and Sesti, Valentina and Bertarelli, Chiara and Lanzani, Guglielmo and Asally, Munehiro and Patern{\`o}, Giuseppe Maria},
  year = {2023},
  journal = {Advanced Science},
  volume = {10},
  number = {8},
  pages = {2205007},
  issn = {2198-3844},
  doi = {10.1002/advs.202205007},
  urldate = {2024-07-19},
  abstract = {Recent studies have shown that bacterial membrane potential is dynamic and plays signaling roles. Yet, little is still known about the mechanisms of membrane potential dynamics regulation---owing to a scarcity of appropriate research tools. Optical modulation of bacterial membrane potential could fill this gap and provide a new approach for studying and controlling bacterial physiology and electrical signaling. Here, the authors show that a membrane-targeted azobenzene (Ziapin2) can be used to photo-modulate the membrane potential in cells of the Gram-positive bacterium Bacillus subtilis. It is found that upon exposure to blue--green light ({$\lambda$} = 470 nm), isomerization of Ziapin2 in the bacteria membrane induces hyperpolarization of the potential. To investigate the origin of this phenomenon, ion-channel-deletion strains and ion channel blockers are examined. The authors found that in presence of the chloride channel blocker idanyloxyacetic acid-94 (IAA-94) or in absence of KtrAB potassium transporter, the hyperpolarization response is attenuated. These results reveal that the Ziapin2 isomerization can induce ion channel opening in the bacterial membrane and suggest that Ziapin2 can be used for studying and controlling bacterial electrical signaling. This new optical tool could contribute to better understand various microbial phenomena, such as biofilm electric signaling and antimicrobial resistance.},
  copyright = {{\copyright} 2023 The Authors. Advanced Science published by Wiley-VCH GmbH},
  langid = {english},
  keywords = {bacterial cell electrophysiology,bacterial electrical signaling,bioelectricity,nanomaterials,optostimulation,photonics},
  file = {/home/andonis/Zotero/storage/GKLHSJXX/de Souza-Guerreiro et al. - 2023 - Membrane Targeted Azobenzene Drives Optical Modula.pdf;/home/andonis/Zotero/storage/7EPQMI4N/advs.html}
}

@article{dingModelSelectionTechniques2018,
  title = {Model {{Selection Techniques}}: {{An Overview}}},
  shorttitle = {Model {{Selection Techniques}}},
  author = {Ding, Jie and Tarokh, Vahid and Yang, Yuhong},
  year = {2018},
  month = nov,
  journal = {IEEE Signal Processing Magazine},
  volume = {35},
  number = {6},
  pages = {16--34},
  issn = {1053-5888, 1558-0792},
  doi = {10.1109/MSP.2018.2867638},
  urldate = {2024-09-09},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}

@article{dysonMeetingEnricoFermi2004,
  title = {A Meeting with {{Enrico Fermi}}},
  author = {Dyson, Freeman},
  year = {2004},
  month = jan,
  journal = {Nature},
  volume = {427},
  number = {6972},
  pages = {297--297},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/427297a},
  urldate = {2023-06-21},
  abstract = {How one intuitive physicist rescued a team from fruitless research.},
  copyright = {2004 Springer Nature Limited},
  langid = {english},
  keywords = {Humanities and Social Sciences,multidisciplinary,Science},
  file = {/home/andonis/Zotero/storage/8VD3PX9H/Dyson - 2004 - A meeting with Enrico Fermi.pdf;/home/andonis/Zotero/storage/6QR4DBA5/427297a.html}
}

@misc{EnsembleSINDyRobustSparse,
  title = {Ensemble-{{SINDy}}: {{Robust}} Sparse Model Discovery in the Low-Data, High-Noise Limit, with Active Learning and Control},
  shorttitle = {Ensemble-{{SINDy}}},
  doi = {10.1098/rspa.2021.0904},
  urldate = {2023-10-30},
  howpublished = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2021.0904},
  langid = {english},
  file = {/home/andonis/Zotero/storage/LVTHB8KP/Ensemble-SINDy Robust sparse model discovery in t.pdf}
}

@article{fanChallengesBigData2014,
  title = {Challenges of {{Big Data}} Analysis},
  author = {Fan, Jianqing and Han, Fang and Liu, Han},
  year = {2014},
  month = jun,
  journal = {National Science Review},
  volume = {1},
  number = {2},
  pages = {293--314},
  issn = {2095-5138},
  doi = {10.1093/nsr/nwt032},
  urldate = {2024-09-17},
  abstract = {Big Data bring new opportunities to modern society and challenges to data scientists. On the one hand, Big Data hold great promises for discovering subtle population patterns and heterogeneities that are not possible with small-scale data. On the other hand, the massive sample size and high dimensionality of Big Data introduce unique computational and statistical challenges, including scalability and storage bottleneck, noise accumulation, spurious correlation, incidental endogeneity and measurement errors. These challenges are distinguished and require new computational and statistical paradigm. This paper gives overviews on the salient features of Big Data and how these features impact on paradigm change on statistical and computational methods as well as computing architectures. We also provide various new perspectives on the Big Data analysis and computation. In particular, we emphasize on the viability of the sparsest solution in high-confidence set and point out that exogenous assumptions in most statistical methods for Big Data cannot be validated due to incidental endogeneity. They can lead to wrong statistical inferences and consequently wrong scientific conclusions.},
  file = {/home/andonis/Zotero/storage/E4CACNEG/Fan et al. - 2014 - Challenges of Big Data analysis.pdf;/home/andonis/Zotero/storage/KNZLRS2N/1397586.html}
}

@article{faselEnsembleSINDyRobustSparse2022,
  title = {Ensemble-{{SINDy}}: {{Robust}} Sparse Model Discovery in the Low-Data, High-Noise Limit, with Active Learning and Control},
  shorttitle = {Ensemble-{{SINDy}}},
  author = {Fasel, U. and Kutz, J. N. and Brunton, B. W. and Brunton, S. L.},
  year = {2022},
  month = apr,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {478},
  number = {2260},
  pages = {20210904},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2021.0904},
  urldate = {2023-11-22},
  abstract = {Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of~the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/EYDUY2LF/Fasel et al. - 2022 - Ensemble-SINDy Robust sparse model discovery in t.pdf}
}

@article{ferrettiBuildingGeneralLangevin2020,
  title = {Building {{General Langevin Models}} from {{Discrete Datasets}}},
  author = {Ferretti, Federica and Chard{\`e}s, Victor and Mora, Thierry and Walczak, Aleksandra M. and Giardina, Irene},
  year = {2020},
  month = jul,
  journal = {Physical Review X},
  volume = {10},
  number = {3},
  pages = {031018},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.10.031018},
  urldate = {2023-10-09},
  langid = {english},
  file = {/home/andonis/Zotero/storage/DY3K8NGZ/Ferretti et al. - 2020 - Building General Langevin Models from Discrete Dat.pdf}
}

@article{friedrichHowQuantifyDeterministic2000,
  title = {How to {{Quantify Deterministic}} and {{Random Influences}} on the {{Statistics}} of the {{Foreign Exchange Market}}},
  author = {Friedrich, R. and Peinke, J. and Renner, {\relax Ch}.},
  year = {2000},
  month = may,
  journal = {Physical Review Letters},
  volume = {84},
  number = {22},
  pages = {5224--5227},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.84.5224},
  urldate = {2024-02-06},
  abstract = {It is shown that price changes of the U.S. dollar--German mark exchange rates upon different delay times can be regarded as a stochastic Marcovian process. Furthermore, we show how Kramers-Moyal coefficients can be estimated from the empirical data. Finally, we present an explicit Fokker-Planck equation which models very precisely the empirical probability distributions, in particular, their non-Gaussian heavy tails.},
  file = {/home/andonis/Zotero/storage/6ILLCT8A/Friedrich et al. - 2000 - How to Quantify Deterministic and Random Influence.pdf}
}

@article{frishmanLearningForceFields2020,
  title = {Learning {{Force Fields}} from {{Stochastic Trajectories}}},
  author = {Frishman, Anna and Ronceray, Pierre},
  year = {2020},
  month = apr,
  journal = {Physical Review X},
  volume = {10},
  number = {2},
  pages = {021009},
  issn = {2160-3308},
  doi = {10.1103/PhysRevX.10.021009},
  urldate = {2023-05-16},
  langid = {english},
  file = {/home/andonis/Zotero/storage/XB4SLMG6/Frishman et Ronceray - 2020 - Learning Force Fields from Stochastic Trajectories.pdf}
}

@article{gaoAutonomousInferenceComplex2022,
  title = {Autonomous Inference of Complex Network Dynamics from Incomplete and Noisy Data},
  author = {Gao, Ting-Ting and Yan, Gang},
  year = {2022},
  month = mar,
  journal = {Nature Computational Science},
  volume = {2},
  number = {3},
  pages = {160--168},
  publisher = {Nature Publishing Group},
  issn = {2662-8457},
  doi = {10.1038/s43588-022-00217-0},
  urldate = {2023-10-12},
  abstract = {The availability of empirical data that capture the structure and behaviour of complex networked systems has been greatly increased in recent years; however, a versatile computational toolbox for unveiling a complex system's nodal and interaction dynamics from data remains elusive. Here we develop a two-phase approach for the autonomous inference of complex network dynamics, and its effectiveness is demonstrated by the tests of inferring neuronal, genetic, social and coupled oscillator dynamics on various synthetic and real networks. Importantly, the approach is robust to incompleteness and noises, including low resolution, observational and dynamical noises, missing and spurious links, and dynamical heterogeneity. We apply the two-phase approach to infer the early spreading dynamics of influenza A flu on the worldwide airline network, and the inferred dynamical equation can also capture the spread of severe acute respiratory syndrome and coronavirus disease 2019. These findings together offer an avenue to discover the hidden microscopic mechanisms of a broad array of real networked systems.},
  copyright = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Complex networks,Computational science,Infectious diseases},
  file = {/home/andonis/Zotero/storage/J4SPU725/Gao et Yan - 2022 - Autonomous inference of complex network dynamics f.pdf}
}

@article{gaoDatadrivenInferenceComplex2023,
  title = {Data-Driven Inference of Complex System Dynamics: {{A}} Mini-Review},
  shorttitle = {Data-Driven Inference of Complex System Dynamics},
  author = {Gao, Ting-Ting and Yan, Gang},
  year = {2023},
  month = apr,
  journal = {Europhysics Letters},
  volume = {142},
  number = {1},
  pages = {11001},
  issn = {0295-5075, 1286-4854},
  doi = {10.1209/0295-5075/acc3bf},
  urldate = {2023-10-10},
  abstract = {Our ability to observe the network topology and nodes' behaviors of complex systems has significantly advanced in the past decade, giving rise to a new and fast-developing frontier ---inferring the underlying dynamical mechanisms of complex systems from the observation data. Here we explain the rationale of data-driven dynamics inference and review the recent progress in this emerging field. Specifically, we classify the existing methods of dynamics inference into three categories, and describe their key ideas, representative applications and limitations. We also discuss the remaining challenges that are worth the future effort.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/NWRTWFSQ/Gao et Yan - 2023 - Data-driven inference of complex system dynamics .pdf}
}

@book{georgesPhysiqueStatistiquePolytechnique,
  title = {Physique {{Statistique Polytechnique}}},
  author = {Georges, Antoine and M{\'e}zard, Marc},
  file = {/home/andonis/Zotero/storage/35REQ34R/_.pdf}
}

@article{gladrowBrokenDetailedBalance2016,
  title = {Broken {{Detailed Balance}} of {{Filament Dynamics}} in {{Active Networks}}},
  author = {Gladrow, J. and Fakhri, N. and MacKintosh, F. C. and Schmidt, C. F. and Broedersz, C. P.},
  year = {2016},
  month = jun,
  journal = {Physical Review Letters},
  volume = {116},
  number = {24},
  pages = {248301},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.116.248301},
  urldate = {2024-09-19},
  abstract = {Myosin motor proteins drive vigorous steady-state fluctuations in the actin cytoskeleton of cells. Endogenous embedded semiflexible filaments such as microtubules, or added filaments such as single-walled carbon nanotubes are used as novel tools to noninvasively track equilibrium and nonequilibrium fluctuations in such biopolymer networks. Here, we analytically calculate shape fluctuations of semiflexible probe filaments in a viscoelastic environment, driven out of equilibrium by motor activity. Transverse bending fluctuations of the probe filaments can be decomposed into dynamic normal modes. We find that these modes no longer evolve independently under nonequilibrium driving. This effective mode coupling results in nonzero circulatory currents in a conformational phase space, reflecting a violation of detailed balance. We present predictions for the characteristic frequencies associated with these currents and investigate how the temporal signatures of motor activity determine mode correlations, which we find to be consistent with recent experiments on microtubules embedded in cytoskeletal networks.},
  file = {/home/andonis/Zotero/storage/ZDAG2B5Y/Gladrow et al. - 2016 - Broken Detailed Balance of Filament Dynamics in Active Networks.pdf;/home/andonis/Zotero/storage/7784GTFP/PhysRevLett.116.html}
}

@article{goldwynStochasticDifferentialEquation2011,
  title = {Stochastic Differential Equation Models for Ion Channel Noise in {{Hodgkin-Huxley}} Neurons},
  author = {Goldwyn, Joshua H. and Imennov, Nikita S. and Famulare, Michael and {Shea-Brown}, Eric},
  year = {2011},
  month = apr,
  journal = {Physical Review E},
  volume = {83},
  number = {4},
  pages = {041908},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.83.041908},
  urldate = {2023-05-31},
  langid = {english},
  file = {/home/andonis/Zotero/storage/NHYTNQ9R/Goldwyn et al. - 2011 - Stochastic differential equation models for ion ch.pdf}
}

@article{hasselmannStochasticClimateModels1976,
  title = {Stochastic Climate Models: {{Part I}}. {{Theory}}},
  shorttitle = {Stochastic Climate Models},
  author = {Hasselmann, K.},
  year = {1976},
  month = jan,
  journal = {Tellus A: Dynamic Meteorology and Oceanography},
  volume = {28},
  number = {6},
  pages = {473},
  issn = {1600-0870},
  doi = {10.3402/tellusa.v28i6.11316},
  urldate = {2024-09-19},
  file = {/home/andonis/Zotero/storage/5N6JIFKS/Hasselmann - 1976 - Stochastic climate models Part I. Theory.pdf}
}

@article{hoebeControlledLightexposureMicroscopy2007,
  title = {Controlled Light-Exposure Microscopy Reduces Photobleaching and Phototoxicity in Fluorescence Live-Cell Imaging},
  author = {Hoebe, R. A. and Van Oven, C. H. and Gadella, T. W. J. and Dhonukshe, P. B. and Van Noorden, C. J. F. and Manders, E. M. M.},
  year = {2007},
  month = feb,
  journal = {Nature Biotechnology},
  volume = {25},
  number = {2},
  pages = {249--253},
  publisher = {Nature Publishing Group},
  issn = {1546-1696},
  doi = {10.1038/nbt1278},
  urldate = {2024-02-02},
  abstract = {Fluorescence microscopy of living cells enables visualization of the dynamics and interactions of intracellular molecules. However, fluorescence live-cell imaging is limited by photobleaching and phototoxicity induced by the excitation light. Here we describe controlled light-exposure microscopy (CLEM), a simple imaging approach that reduces photobleaching and phototoxicity two- to tenfold, depending on the fluorophore distribution in the object. By spatially controlling the light-exposure time, CLEM reduces the excitation-light dose without compromising image quality. We show that CLEM reduces photobleaching sevenfold in tobacco plant cells expressing microtubule-associated GFP-MAP4 and reduces production of reactive oxygen species eightfold and prolongs cell survival sixfold in HeLa cells expressing chromatin-associated H2B-GFP. In addition, CLEM increases the dynamic range of the fluorescence intensity at least twofold.},
  copyright = {2007 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Agriculture,Bioinformatics,Biomedical Engineering/Biotechnology,Biomedicine,Biotechnology,general,Life Sciences}
}

@article{hozeHeterogeneityAMPAReceptor2012,
  title = {Heterogeneity of {{AMPA}} Receptor Trafficking and Molecular Interactions Revealed by Superresolution Analysis of Live Cell Imaging},
  author = {Hoze, Nathanael and Nair, Deepak and Hosy, Eric and Sieben, Christian and Manley, Suliana and Herrmann, Andreas and Sibarita, Jean-Baptiste and Choquet, Daniel and Holcman, David},
  year = {2012},
  month = oct,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {109},
  number = {42},
  pages = {17052--17057},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.1204589109},
  urldate = {2024-09-19},
  abstract = {Simultaneous tracking of many thousands of individual particles in live cells is possible now with the advent of high-density superresolution imaging methods. We present an approach to extract local biophysical properties of cell-particle interaction from such newly acquired large collection of data. Because classical methods do not keep the spatial localization of individual trajectories, it is not possible to access localized biophysical parameters. In contrast, by combining the high-density superresolution imaging data with the present analysis, we determine the local properties of protein dynamics. We specifically focus on AMPA receptor (AMPAR) trafficking and estimate the strength of their molecular interaction at the subdiffraction level in hippocampal dendrites. These interactions correspond to attracting potential wells of large size, showing that the high density of AMPARs is generated by physical interactions with an ensemble of cooperative membrane surface binding sites, rather than molecular crowding or aggregation, which is the case for the membrane viral glycoprotein VSVG. We further show that AMPARs can either be pushed in or out of dendritic spines. Finally, we characterize the recurrent step of influenza trajectories. To conclude, the present analysis allows the identification of the molecular organization responsible for the heterogeneities of random trajectories in cells.},
  file = {/home/andonis/Zotero/storage/QBKRRQKE/Hoze et al. - 2012 - Heterogeneity of AMPA receptor trafficking and molecular interactions revealed by superresolution an.pdf}
}

@article{huynhInferringDensitydependentPopulation2023,
  title = {Inferring Density-Dependent Population Dynamics Mechanisms through Rate Disambiguation for Logistic Birth-Death Processes},
  author = {Huynh, Linh and Scott, Jacob G. and Thomas, Peter J.},
  year = {2023},
  month = mar,
  journal = {Journal of Mathematical Biology},
  volume = {86},
  number = {4},
  pages = {50},
  issn = {1432-1416},
  doi = {10.1007/s00285-023-01877-w},
  urldate = {2023-06-02},
  abstract = {Density dependence is important in the ecology and evolution of microbial and cancer cells. Typically, we can only measure net growth rates, but the underlying density-dependent mechanisms that give rise to the observed dynamics can manifest in birth processes, death processes, or both. Therefore, we utilize the mean and variance of cell number fluctuations to separately identify birth and death rates from time series that follow stochastic birth-death processes with logistic growth. Our nonparametric method provides a novel perspective on stochastic parameter identifiability, which we validate by analyzing the accuracy in terms of the discretization bin size. We apply our method to the scenario where a homogeneous cell population goes through three stages: (1) grows naturally to its carrying capacity, (2) is treated with a drug that reduces its carrying capacity, and (3) overcomes the drug effect to restore its original carrying capacity. In each stage, we disambiguate whether the dynamics occur through the birth process, death process, or some combination of the two, which contributes to understanding drug resistance mechanisms. In the case of limited sample sizes, we provide an alternative method based on maximum likelihood and solve a constrained nonlinear optimization problem to identify the most likely density dependence parameter for a given cell number time series. Our methods can be applied to other biological systems at different scales to disambiguate density-dependent mechanisms underlying the same net growth rate.},
  langid = {english},
  keywords = {60J25,60J27,62M10,92D25,Density-dependent ecological modeling,Drug resistance,Parameter identifiability,Stochastic discretization error analysis,Stochastic processes,Uncertainty quantification},
  file = {/home/andonis/Zotero/storage/KR49TR8T/Huynh et al. - 2023 - Inferring density-dependent population dynamics me.pdf}
}

@misc{kaptanogluBenchmarkingSparseSystem2023,
  title = {Benchmarking Sparse System Identification with Low-Dimensional Chaos},
  author = {Kaptanoglu, Alan A. and Zhang, Lanyue and Nicolaou, Zachary G. and Fasel, Urban and Brunton, Steven L.},
  year = {2023},
  month = feb,
  number = {arXiv:2302.10787},
  eprint = {2302.10787},
  primaryclass = {physics},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.10787},
  urldate = {2023-12-12},
  abstract = {Sparse system identification is the data-driven process of obtaining parsimonious differential equations that describe the evolution of a dynamical system, balancing model complexity and accuracy. There has been rapid innovation in system identification across scientific domains, but there remains a gap in the literature for large-scale methodological comparisons that are evaluated on a variety of dynamical systems. In this work, we systematically benchmark sparse regression variants by utilizing the dysts standardized database of chaotic systems. In particular, we demonstrate how this open-source tool can be used to quantitatively compare different methods of system identification. To illustrate how this benchmark can be utilized, we perform a large comparison of four algorithms for solving the sparse identification of nonlinear dynamics (SINDy) optimization problem, finding strong performance of the original algorithm and a recent mixed-integer discrete algorithm. In all cases, we used ensembling to improve the noise robustness of SINDy and provide statistical comparisons. In addition, we show very compelling evidence that the weak SINDy formulation provides significant improvements over the traditional method, even on clean data. Lastly, we investigate how Pareto-optimal models generated from SINDy algorithms depend on the properties of the equations, finding that the performance shows no significant dependence on a set of dynamical properties that quantify the amount of chaos, scale separation, degree of nonlinearity, and the syntactic complexity.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Physics - Data Analysis Statistics and Probability},
  file = {/home/andonis/Zotero/storage/KWUZSI4S/Kaptanoglu et al. - 2023 - Benchmarking sparse system identification with low.pdf;/home/andonis/Zotero/storage/ZU73NLAY/2302.html}
}

@misc{kaptanogluBenchmarkingSparseSystem2023a,
  title = {Benchmarking Sparse System Identification with Low-Dimensional Chaos},
  author = {Kaptanoglu, Alan A. and Zhang, Lanyue and Nicolaou, Zachary G. and Fasel, Urban and Brunton, Steven L.},
  year = {2023},
  month = feb,
  number = {arXiv:2302.10787},
  eprint = {2302.10787},
  primaryclass = {physics},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.10787},
  urldate = {2023-12-12},
  abstract = {Sparse system identification is the data-driven process of obtaining parsimonious differential equations that describe the evolution of a dynamical system, balancing model complexity and accuracy. There has been rapid innovation in system identification across scientific domains, but there remains a gap in the literature for large-scale methodological comparisons that are evaluated on a variety of dynamical systems. In this work, we systematically benchmark sparse regression variants by utilizing the dysts standardized database of chaotic systems. In particular, we demonstrate how this open-source tool can be used to quantitatively compare different methods of system identification. To illustrate how this benchmark can be utilized, we perform a large comparison of four algorithms for solving the sparse identification of nonlinear dynamics (SINDy) optimization problem, finding strong performance of the original algorithm and a recent mixed-integer discrete algorithm. In all cases, we used ensembling to improve the noise robustness of SINDy and provide statistical comparisons. In addition, we show very compelling evidence that the weak SINDy formulation provides significant improvements over the traditional method, even on clean data. Lastly, we investigate how Pareto-optimal models generated from SINDy algorithms depend on the properties of the equations, finding that the performance shows no significant dependence on a set of dynamical properties that quantify the amount of chaos, scale separation, degree of nonlinearity, and the syntactic complexity.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Systems and Control,Physics - Data Analysis Statistics and Probability},
  file = {/home/andonis/Zotero/storage/SIAZAN9K/Kaptanoglu et al. - 2023 - Benchmarking sparse system identification with low.pdf;/home/andonis/Zotero/storage/9SX52QRQ/2302.html}
}

@article{kaptanogluPySINDyComprehensivePython2022,
  title = {{{PySINDy}}: {{A}} Comprehensive {{Python}} Package for Robust Sparse System Identification},
  shorttitle = {{{PySINDy}}},
  author = {Kaptanoglu, Alan A. and de Silva, Brian M. and Fasel, Urban and Kaheman, Kadierdan and Goldschmidt, Andy J. and Callaham, Jared and Delahunt, Charles B. and Nicolaou, Zachary G. and Champion, Kathleen and Loiseau, Jean-Christophe and Kutz, J. Nathan and Brunton, Steven L.},
  year = {2022},
  month = jan,
  journal = {Journal of Open Source Software},
  volume = {7},
  number = {69},
  pages = {3994},
  issn = {2475-9066},
  doi = {10.21105/joss.03994},
  urldate = {2024-02-05},
  abstract = {Kaptanoglu et al., (2022). PySINDy: A comprehensive Python package for robust sparse system identification. Journal of Open Source Software, 7(69), 3994, https://doi.org/10.21105/joss.03994},
  langid = {english},
  file = {/home/andonis/Zotero/storage/WAZRE99V/Kaptanoglu et al. - 2022 - PySINDy A comprehensive Python package for robust.pdf}
}

@article{kidgerNeuralSDEsInfiniteDimensional,
  title = {Neural {{SDEs}} as {{Infinite-Dimensional GANs}}},
  author = {Kidger, Patrick and Foster, James and Li, Xuechen and Oberhauser, Harald and Lyons, Terry},
  abstract = {Stochastic differential equations (SDEs) are a staple of mathematical modelling of temporal dynamics. However, a fundamental limitation has been that such models have typically been relatively inflexible, which recent work introducing Neural SDEs has sought to solve. Here, we show that the current classical approach to fitting SDEs may be approached as a special case of (Wasserstein) GANs, and in doing so the neural and classical regimes may be brought together. The input noise is Brownian motion, the output samples are time-evolving paths produced by a numerical solver, and by parameterising a discriminator as a Neural Controlled Differential Equation (CDE), we obtain Neural SDEs as (in modern machine learning parlance) continuous-time generative time series models. Unlike previous work on this problem, this is a direct extension of the classical approach without reference to either prespecified statistics or density functions. Arbitrary drift and diffusions are admissible, so as the Wasserstein loss has a unique global minima, in the infinite data limit any SDE may be learnt. Example code has been made available as part of the torchsde repository.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/LKX5RXMT/Kidger et al. - Neural SDEs as Inﬁnite-Dimensional GANs.pdf}
}

@incollection{kloedenStochasticTaylorExpansions1992,
  title = {Stochastic {{Taylor Expansions}}},
  booktitle = {Numerical {{Solution}} of {{Stochastic Differential Equations}}},
  author = {Kloeden, Peter E. and Platen, Eckhard},
  editor = {Kloeden, Peter E. and Platen, Eckhard},
  year = {1992},
  pages = {161--226},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-12616-5_5},
  urldate = {2025-02-14},
  abstract = {In this chapter stochastic Taylor expansions are derived and investigated. They generalize the deterministic Taylor formula as well as the Ito formula and allow various kinds of higher order approximations of functionals of diffusion processes to be made. These expansions are the key to the stochastic numerical analysis which we shall develop in the second half of this book. Apart from Section 1, which provides an introductory overview, this chapter could be omitted at the first reading of the book.},
  isbn = {978-3-662-12616-5},
  langid = {english},
  keywords = {Coefficient Function,Polynomial Growth,Stochastic Differential Equation,TAYLOR Expansion,Wiener Process},
  file = {/home/andonis/Zotero/storage/BFF8IIHP/Kloeden et Platen - 1992 - Stochastic Taylor Expansions.pdf}
}

@book{konishiInformationCriteriaStatistical2008,
  title = {Information {{Criteria}} and {{Statistical Modeling}}},
  author = {Konishi, Sadanori and Kitagawa, Genshiro},
  year = {2008},
  series = {Springer {{Series}} in {{Statistics}}},
  publisher = {Springer New York},
  address = {New York, NY},
  doi = {10.1007/978-0-387-71887-3},
  urldate = {2024-02-29},
  isbn = {978-0-387-71886-6 978-0-387-71887-3},
  file = {/home/andonis/Zotero/storage/32QIX9K6/Konishi et Kitagawa - 2008 - Information Criteria and Statistical Modeling.pdf}
}

@article{krzakalaStatisticalPhysicsMethods,
  title = {Statistical {{Physics Methods}} in {{Optimization}} and {{Machine Learning}}},
  author = {Krzakala, Florent and Zdeborov{\'a}, Lenka},
  langid = {english},
  file = {/home/andonis/Zotero/storage/I7KJRHHN/Krzakala et Zdeborová - Statistical Physics Methods in Optimization and Machine Learning.pdf}
}

@article{laurentMappingSpatiotemporalDynamics2019,
  title = {Mapping Spatio-Temporal Dynamics of Single Biomolecules in Living Cells},
  author = {Laurent, Fran{\c c}ois and Floderer, Charlotte and Favard, Cyril and Muriaux, Delphine and Masson, Jean-Baptiste and Vestergaard, Christian L},
  year = {2019},
  month = nov,
  journal = {Physical Biology},
  volume = {17},
  number = {1},
  pages = {015003},
  issn = {1478-3975},
  doi = {10.1088/1478-3975/ab5167},
  urldate = {2024-05-14},
  file = {/home/andonis/Zotero/storage/C2SFXUVP/Laurent et al. - 2019 - Mapping spatio-temporal dynamics of single biomole.pdf}
}

@article{lauStatedependentDiffusionThermodynamic2007,
  title = {State-Dependent Diffusion: {{Thermodynamic}} Consistency and Its Path Integral Formulation},
  shorttitle = {State-Dependent Diffusion},
  author = {Lau, A. W. C. and Lubensky, T. C.},
  year = {2007},
  month = jul,
  journal = {Physical Review E},
  volume = {76},
  number = {1},
  pages = {011123},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.76.011123},
  urldate = {2024-05-15},
  abstract = {The friction coefficient of a particle can depend on its position, as it does when the particle is near a wall. We formulate the dynamics of particles with such state-dependent friction coefficients in terms of a general Langevin equation with multiplicative noise, whose evaluation requires the introduction of specific rules. Two common conventions, the Ito and the Stratonovich, provide alternative rules for evaluation of the noise, but other conventions are possible. We show that the requirement that a particle's distribution function approach the Boltzmann distribution at long times dictates that a drift term must be added to the Langevin equation. This drift term is proportional to the derivative of the diffusion coefficient times a factor that depends on the convention used to define the multiplicative noise. We explore the consequences of this result in a number of examples with spatially varying diffusion coefficients. We also derive a path integral representation for arbitrary interpretation of the noise, and use it in a perturbative study of correlations in a simple system.},
  file = {/home/andonis/Zotero/storage/WI8VPQXA/Lau et Lubensky - 2007 - State-dependent diffusion Thermodynamic consisten.pdf}
}

@misc{LearningPartialDifferential,
  title = {Learning Partial Differential Equations via Data Discovery and Sparse Optimization {\textbar} {{Proceedings}} of the {{Royal Society A}}: {{Mathematical}}, {{Physical}} and {{Engineering Sciences}}},
  urldate = {2022-11-29},
  howpublished = {https://royalsocietypublishing.org/doi/10.1098/rspa.2016.0446}
}

@misc{LearningPartialDifferentiala,
  title = {Learning Partial Differential Equations via Data Discovery and Sparse Optimization - Royalsocietypublishing.Org/},
  doi = {10.1098/rspa.2016.0446},
  urldate = {2023-05-16},
  howpublished = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2016.0446},
  langid = {english},
  file = {/home/andonis/Zotero/storage/GEDEL96E/Learning partial differential equations via data d.pdf;/home/andonis/Zotero/storage/U3ANGQSM/rspa.2016.html}
}

@misc{LearningPartialDifferentialb,
  title = {Learning Partial Differential Equations via Data Discovery and Sparse Optimization - Royalsocietypublishing.Org/},
  doi = {10.1098/rspa.2016.0446},
  urldate = {2023-05-16},
  howpublished = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2016.0446},
  langid = {english},
  file = {/home/andonis/Zotero/storage/8TRUG664/Learning partial differential equations via data d.pdf;/home/andonis/Zotero/storage/9VRZVQVW/rspa.2016.html}
}

@misc{LearningStochasticClosures,
  title = {Learning Stochastic Closures Using Ensemble {{Kalman}} Inversion {\textbar} {{Transactions}} of {{Mathematics}} and {{Its Applications}} {\textbar} {{Oxford Academic}} - Academic.Oup.Com/},
  urldate = {2022-11-23},
  howpublished = {https://academic.oup.com/imatrm/article/5/1/tnab003/6460773?login=false},
  file = {/home/andonis/Zotero/storage/AWPSSU33/6460773.html}
}

@article{lebarbierIntroductionAuCritere2006,
  title = {{Une introduction au crit{\`e}re BIC : fondements th{\'e}oriques et interpr{\'e}tation}},
  shorttitle = {{Une introduction au crit{\`e}re BIC}},
  author = {Lebarbier, {\'E}milie and {Mary-Huard}, Tristan},
  year = {2006},
  journal = {Journal de la soci{\'e}t{\'e} fran{\c c}aise de statistique},
  volume = {147},
  number = {1},
  pages = {39--57},
  publisher = {Soci{\'e}t{\'e} fran{\c c}aise de statistique},
  issn = {1962-5197},
  urldate = {2024-09-09},
  langid = {fra},
  file = {/home/andonis/Zotero/storage/TDHS7HBH/199589.html}
}

@article{leeLpregularizationEnsembleKalman,
  title = {Lp-Regularization for {{Ensemble Kalman Inversion}}},
  author = {Lee, Yoonsang},
  journal = {Inverse problems},
  pages = {30},
  langid = {english},
  file = {/home/andonis/Zotero/storage/ZNNPMXF9/Lee - lp-regularization for Ensemble Kalman Inversion.pdf}
}

@article{lemonLivecellImagingEra2020,
  title = {Live-Cell Imaging in the Era of Too Many Microscopes},
  author = {Lemon, William C. and McDole, Katie},
  year = {2020},
  month = oct,
  journal = {Current Opinion in Cell Biology},
  volume = {66},
  pages = {34--42},
  issn = {09550674},
  doi = {10.1016/j.ceb.2020.04.008},
  urldate = {2024-09-20},
  langid = {english}
}

@article{lemonLivecellImagingEra2020a,
  title = {Live-Cell Imaging in the Era of Too Many Microscopes},
  author = {Lemon, William C. and McDole, Katie},
  year = {2020},
  month = oct,
  journal = {Current Opinion in Cell Biology},
  volume = {66},
  pages = {34--42},
  issn = {1879-0410},
  doi = {10.1016/j.ceb.2020.04.008},
  abstract = {At the time of this writing, searching Google Scholar for 'light-sheet microscopy' returns almost 8500 results; over three-quarters of which were published in the last 5 years alone. Searching for other advanced imaging methods in the last 5 years yields similar results: 'super-resolution microscopy' ({$>$}16 000), 'single-molecule imaging' (almost 10 000), SPIM (Single Plane Illumination Microscopy, 5000), and 'lattice light-sheet' (1300). The explosion of new imaging methods has also produced a dizzying menagerie of acronyms, with over 100 different species of 'light-sheet' alone, from SPIM to UM (Ultra microscopy) to SiMView (Simultaneous MultiView) to iSPIM (inclined SPIM, not to be confused with iSPIM, inverted SPIM). How then is the average biologist, without an advanced degree in physics, optics, or computer science supposed to make heads or tails of which method is best suited for their needs? Let us also not forget the plight of the optical physicist, who at best might need help with obtaining healthy samples and keeping them that way, or at worst may not realize the impact their newest technique could have for biologists. This review will not attempt to solve all~these problems, but instead highlight some of the most recent, successful mergers between biology and advanced imaging technologies, as well as hopefully provide some guidance for anyone interested in journeying into the world of live-cell imaging.},
  langid = {english},
  pmid = {32470820},
  keywords = {Advanced imaging,Animals,Cell Survival,Fluorescence,Humans,Imaging Three-Dimensional,Imaging tools,Light-sheet microscopy,Live-cell imaging,Microscopy,Staining and Labeling,Super-resolution microscopy}
}

@article{lemonLivecellImagingEra2020b,
  title = {Live-Cell Imaging in the Era of Too Many Microscopes},
  author = {Lemon, William C. and McDole, Katie},
  year = {2020},
  month = oct,
  journal = {Current Opinion in Cell Biology},
  series = {Cell {{Dynamics}}},
  volume = {66},
  pages = {34--42},
  issn = {0955-0674},
  doi = {10.1016/j.ceb.2020.04.008},
  urldate = {2024-09-20},
  abstract = {At the time of this writing, searching Google Scholar for `light-sheet microscopy' returns almost 8500 results; over three-quarters of which were published in the last 5 years alone. Searching for other advanced imaging methods in the last 5 years yields similar results: `super-resolution microscopy' ({$>$}16 000), `single-molecule imaging' (almost 10 000), SPIM (Single Plane Illumination Microscopy, 5000), and `lattice light-sheet' (1300). The explosion of new imaging methods has also produced a dizzying menagerie of acronyms, with over 100 different species of `light-sheet' alone, from SPIM to UM (Ultra microscopy) to SiMView (Simultaneous MultiView) to iSPIM (inclined SPIM, not to be confused with iSPIM, inverted SPIM). How then is the average biologist, without an advanced degree in physics, optics, or computer science supposed to make heads or tails of which method is best suited for their needs? Let us also not forget the plight of the optical physicist, who at best might need help with obtaining healthy samples and keeping them that way, or at worst may not realize the impact their newest technique could have for biologists. This review will not attempt to solve all~these problems, but instead highlight some of the most recent, successful mergers between biology and advanced imaging technologies, as well as hopefully provide some guidance for anyone interested in journeying into the world of live-cell imaging.},
  keywords = {Advanced imaging,Imaging tools,Light-sheet microscopy,Live-cell imaging,Microscopy,Super-resolution microscopy},
  file = {/home/andonis/Zotero/storage/JW37UKSZ/S0955067420300545.html}
}

@inproceedings{levisInferenceBlackHole2021,
  title = {Inference of {{Black Hole Fluid-Dynamics}} from {{Sparse Interferometric Measurements}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Levis, Aviad and Lee, Daeyoung and Tropp, Joel A. and Gammie, Charles F. and Bouman, Katherine L.},
  year = {2021},
  month = oct,
  pages = {2320--2329},
  publisher = {IEEE},
  address = {Montreal, QC, Canada},
  doi = {10.1109/ICCV48922.2021.00234},
  urldate = {2022-11-18},
  abstract = {We develop an approach to recover the underlying properties of fluid-dynamical processes from sparse measurements. We are motivated by the task of imaging the stochastically evolving environment surrounding black holes, and demonstrate how flow parameters can be estimated from sparse interferometric measurements used in radio astronomical imaging. To model the stochastic flow we use spatio-temporal Gaussian Random Fields (GRFs). The high dimensionality of the underlying source video makes direct representation via a GRF's full covariance matrix intractable. In contrast, stochastic partial differential equations are able to capture correlations at multiple scales by specifying only local interaction coefficients. Our approach estimates the coefficients of a space-time diffusion equation that dictates the stationary statistics of the dynamical process. We analyze our approach on realistic simulations of black hole evolution and demonstrate its advantage over state-of-the-art dynamic black hole imaging techniques.},
  isbn = {978-1-6654-2812-5},
  langid = {english},
  file = {/home/andonis/Zotero/storage/3DC6N2C5/Levis et al. - 2021 - Inference of Black Hole Fluid-Dynamics from Sparse.pdf}
}

@article{liDatadrivenApproachDiscovering2021,
  title = {A Data-Driven Approach for Discovering Stochastic Dynamical Systems with Non-{{Gaussian L{\'e}vy}} Noise},
  author = {Li, Yang and Duan, Jinqiao},
  year = {2021},
  month = mar,
  journal = {Physica D: Nonlinear Phenomena},
  volume = {417},
  pages = {132830},
  issn = {01672789},
  doi = {10.1016/j.physd.2020.132830},
  urldate = {2024-05-15},
  abstract = {With the rapid increase of valuable observational, experimental and simulating data for complex systems, great efforts are being devoted to discovering governing laws underlying the evolution of these systems. However, the existing techniques are limited to extract governing laws from data as either deterministic differential equations or stochastic differential equations with Gaussian noise. In the present work, we develop a new data-driven approach to extract stochastic dynamical systems with non-Gaussian symmetric L{\'e}vy noise, as well as Gaussian noise. First, we establish a feasible theoretical framework, by expressing the drift coefficient, diffusion coefficient and jump measure (i.e., anomalous diffusion) for the underlying stochastic dynamical system in terms of sample paths data. We then design a numerical algorithm to compute the drift, diffusion coefficient and jump measure, and thus extract a governing stochastic differential equation with Gaussian and non-Gaussian noise. Finally, we demonstrate the efficacy and accuracy of our approach by applying to several prototypical one-, twoand three-dimensional systems. This new approach will become a tool in discovering governing dynamical laws from noisy data sets, from observing or simulating complex phenomena, such as rare events triggered by random fluctuations with heavy as well as light tail statistical features.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/IMGCB72R/Li et Duan - 2021 - A data-driven approach for discovering stochastic .pdf}
}

@misc{liuKANKolmogorovArnoldNetworks2024,
  title = {{{KAN}}: {{Kolmogorov-Arnold Networks}}},
  shorttitle = {{{KAN}}},
  author = {Liu, Ziming and Wang, Yixuan and Vaidya, Sachin and Ruehle, Fabian and Halverson, James and Solja{\v c}i{\'c}, Marin and Hou, Thomas Y. and Tegmark, Max},
  year = {2024},
  month = jun,
  number = {arXiv:2404.19756},
  eprint = {2404.19756},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.19756},
  urldate = {2024-10-16},
  abstract = {Inspired by the Kolmogorov-Arnold representation theorem, we propose Kolmogorov-Arnold Networks (KANs) as promising alternatives to Multi-Layer Perceptrons (MLPs). While MLPs have fixed activation functions on nodes ("neurons"), KANs have learnable activation functions on edges ("weights"). KANs have no linear weights at all -- every weight parameter is replaced by a univariate function parametrized as a spline. We show that this seemingly simple change makes KANs outperform MLPs in terms of accuracy and interpretability. For accuracy, much smaller KANs can achieve comparable or better accuracy than much larger MLPs in data fitting and PDE solving. Theoretically and empirically, KANs possess faster neural scaling laws than MLPs. For interpretability, KANs can be intuitively visualized and can easily interact with human users. Through two examples in mathematics and physics, KANs are shown to be useful collaborators helping scientists (re)discover mathematical and physical laws. In summary, KANs are promising alternatives for MLPs, opening opportunities for further improving today's deep learning models which rely heavily on MLPs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/8JAZGE7S/Liu et al. - 2024 - KAN Kolmogorov-Arnold Networks.pdf;/home/andonis/Zotero/storage/N2BCZH82/2404.html}
}

@misc{liuNeuralSDEStabilizing2019,
  title = {Neural {{SDE}}: {{Stabilizing Neural ODE Networks}} with {{Stochastic Noise}}},
  shorttitle = {Neural {{SDE}}},
  author = {Liu, Xuanqing and Xiao, Tesi and Si, Si and Cao, Qin and Kumar, Sanjiv and Hsieh, Cho-Jui},
  year = {2019},
  month = jun,
  number = {arXiv:1906.02355},
  eprint = {1906.02355},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-09-05},
  abstract = {Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE) network, which naturally incorporates various commonly used regularization mechanisms based on random noise injection. Our framework can model various types of noise injection frequently used in discrete networks for regularization purpose, such as dropout and additive/multiplicative noise in each block. We provide theoretical analysis explaining the improved robustness of Neural SDE models against input perturbations/adversarial attacks. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/J5YULTHZ/Liu et al. - 2019 - Neural SDE Stabilizing Neural ODE Networks with S.pdf}
}

@article{loBacterialElectrophysiology2024,
  title = {{Bacterial Electrophysiology}},
  author = {Lo, Wei-Chang and Krasnopeeva, Ekaterina and Pilizota, Teuta},
  year = {2024},
  month = jul,
  journal = {Annual Review of Biophysics},
  volume = {53},
  number = {Volume 53, 2024},
  pages = {487--510},
  publisher = {Annual Reviews},
  issn = {1936-122X, 1936-1238},
  doi = {10.1146/annurev-biophys-030822-032215},
  urldate = {2024-07-19},
  abstract = {Bacterial ion fluxes are involved in the generation of energy, transport, and motility. As such, bacterial electrophysiology is fundamentally important for the bacterial life cycle, but it is often neglected and consequently, by and large, not understood. Arguably, the two main reasons for this are the complexity of measuring relevant variables in small cells with a cell envelope that contains the cell wall and the fact that, in a unicellular organism, relevant variables become intertwined in a nontrivial manner. To help give bacterial electrophysiology studies a firm footing, in this review, we go back to basics. We look first at the biophysics of bacterial membrane potential, and then at the approaches and models developed mostly for the study of neurons and eukaryotic mitochondria. We discuss their applicability to bacterial cells. Finally, we connect bacterial membrane potential with other relevant (electro)physiological variables and summarize methods that can be used to both measure and influence bacterial electrophysiology.},
  langid = {french},
  file = {/home/andonis/Zotero/storage/8R8C8GXL/annurev-biophys-030822-032215.html}
}

@article{longPDENet20Learning2019,
  title = {{{PDE-Net}} 2.0: {{Learning PDEs}} from Data with a Numeric-Symbolic Hybrid Deep Network},
  shorttitle = {{{PDE-Net}} 2.0},
  author = {Long, Zichao and Lu, Yiping and Dong, Bin},
  year = {2019},
  month = dec,
  journal = {Journal of Computational Physics},
  volume = {399},
  pages = {108925},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.108925},
  urldate = {2024-09-12},
  abstract = {Partial differential equations (PDEs) are commonly derived based on empirical observations. However, recent advances of technology enable us to collect and store massive amount of data, which offers new opportunities for data-driven discovery of PDEs. In this paper, we propose a new deep neural network, called PDE-Net 2.0, to discover (time-dependent) PDEs from observed dynamic data with minor prior knowledge on the underlying mechanism that drives the dynamics. The design of PDE-Net 2.0 is based on our earlier work [1] where the original version of PDE-Net was proposed. PDE-Net 2.0 is a combination of numerical approximation of differential operators by convolutions and a symbolic multi-layer neural network for model recovery. Comparing with existing approaches, PDE-Net 2.0 has the most flexibility and expressive power by learning both differential operators and the nonlinear response function of the underlying PDE model. Numerical experiments show that the PDE-Net 2.0 has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.},
  keywords = {Convolutional neural network,Dynamic system,Partial differential equations,Symbolic neural network},
  file = {/home/andonis/Zotero/storage/6MVTCXUG/Long et al. - 2019 - PDE-Net 2.0 Learning PDEs from data with a numeric-symbolic hybrid deep network.pdf;/home/andonis/Zotero/storage/FZGRPIQU/S0021999119306308.html}
}

@article{longPDENetLearningPDEs,
  title = {{{PDE-Net}}: {{Learning PDEs}} from {{Data}}},
  author = {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
  abstract = {Partial differential equations (PDEs) play a prominent role in many disciplines of science and engineering. PDEs are commonly derived based on empirical observations. However, with the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDENet, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. Comparing with existing approaches, our approach has the most flexibility by learning both differential operators and the nonlinear response function of the underlying PDE model. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/336KVNMC/Long et al. - PDE-Net Learning PDEs from Data.pdf}
}

@article{LookRidgeRegression2022,
  title = {[{{Look}}] {{Ridge}} Regression = {{L}}\_2 Norm},
  year = {2022},
  month = oct,
  journal = {Wikipedia},
  urldate = {2022-10-20},
  abstract = {Ridge regression is a method of estimating the coefficients of multiple-regression models in scenarios where the independent variables are highly correlated. It has been used in many fields including econometrics, chemistry, and engineering. Also known as Tikhonov regularization, named for Andrey Tikhonov, it is a method of regularization of ill-posed problems. it is particularly useful to mitigate the problem of multicollinearity in linear regression, which commonly occurs in models with large numbers of parameters. In general, the method provides improved efficiency in parameter estimation problems in exchange for a tolerable amount of bias (see bias--variance tradeoff).The theory was first introduced by Hoerl and Kennard in 1970 in their Technometrics papers ``RIDGE regressions: biased estimation of nonorthogonal problems'' and ``RIDGE regressions: applications in nonorthogonal problems''. This was the result of ten years of research into the field of ridge analysis.Ridge regression was developed as a possible solution to the imprecision of least square estimators when linear regression models have some multicollinear (highly correlated) independent variables---by creating a ridge regression estimator (RR). This provides a more precise ridge parameters estimate, as its variance and mean square estimator are often smaller than the least square estimators previously derived.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1116605324},
  file = {/home/andonis/Zotero/storage/B62L5KNX/Ridge_regression.html}
}

@article{madduLearningPhysicallyConsistent2021,
  title = {Learning Physically Consistent Differential Equation Models from Data Using Group Sparsity},
  author = {Maddu, Suryanarayana and Cheeseman, Bevan L. and M{\"u}ller, Christian L. and Sbalzarini, Ivo F.},
  year = {2021},
  month = apr,
  journal = {Physical Review E},
  volume = {103},
  number = {4},
  pages = {042310},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.103.042310},
  urldate = {2023-05-16},
  langid = {english},
  file = {/home/andonis/Zotero/storage/YAARDCUF/Maddu et al. - 2021 - Learning physically consistent differential equati.pdf}
}

@article{madduStabilitySelectionEnables2022,
  title = {Stability Selection Enables Robust Learning of Differential Equations from Limited Noisy Data},
  author = {Maddu, Suryanarayana and Cheeseman, Bevan L. and Sbalzarini, Ivo F. and M{\"u}ller, Christian L.},
  year = {2022},
  month = jun,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {478},
  number = {2262},
  pages = {20210916},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2021.0916},
  urldate = {2022-10-21},
  abstract = {We present a statistical learning framework for robust identification of differential equations from noisy spatio-temporal data. We address two issues that have so far limited the application of such methods, namely their robustness against noise and the need for manual parameter tuning, by proposing stability-based model selection to determine the level of regularization required for reproducible inference. This avoids manual parameter tuning and improves robustness against noise in the data. Our stability selection approach, termed PDE-STRIDE, can be combined with any sparsity-promoting regression method and provides an interpretable criterion for model component importance. We show that the particular combination of stability selection with the iterative hard-thresholding algorithm from compressed sensing provides a fast and robust framework for equation inference that outperforms previous approaches with respect to accuracy, amount of data required, and robustness. We illustrate the performance of PDE-STRIDE on a range of simulated benchmark problems, and we demonstrate the applicability of PDE-STRIDE on real-world data by considering purely data-driven inference of the protein interaction network for embryonic polarization in               Caenorhabditis elegans               . Using fluorescence microscopy images of               C. elegans               zygotes as input data, PDE-STRIDE is able to learn the molecular interactions of the proteins.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/MBZCW4QI/Maddu et al. - 2022 - Stability selection enables robust learning of dif.pdf}
}

@article{majdaMathematicalFrameworkStochastic2001,
  title = {A Mathematical Framework for Stochastic Climate Models},
  author = {Majda, Andrew J. and Timofeyev, Ilya and Vanden Eijnden, Eric},
  year = {2001},
  month = aug,
  journal = {Communications on Pure and Applied Mathematics},
  volume = {54},
  number = {8},
  pages = {891--974},
  issn = {0010-3640, 1097-0312},
  doi = {10.1002/cpa.1014},
  urldate = {2023-10-02},
  langid = {english},
  file = {/home/andonis/Zotero/storage/DY5AUGVN/Majda et al. - 2001 - A mathematical framework for stochastic climate mo.pdf}
}

@article{manganModelSelectionDynamical2017,
  title = {Model Selection for Dynamical Systems via Sparse Regression and Information Criteria},
  author = {Mangan, N. M. and Kutz, J. N. and Brunton, S. L. and Proctor, J. L.},
  year = {2017},
  month = aug,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {473},
  number = {2204},
  pages = {20170009},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2017.0009},
  urldate = {2024-01-12},
  abstract = {We develop an algorithm for model selection which allows for the consideration of a combinatorially large number of candidate models governing a dynamical system. The innovation circumvents a disadvantage of standard model selection which typically limits the number candidate models considered due to the intractability of computing information criteria. Using a recently developed sparse identification of nonlinear dynamics algorithm, the sub-selection of candidate models near the Pareto frontier allows for a tractable computation of AIC (Akaike information criteria) or BIC (Bayes information criteria) scores for the remaining candidate models. The information criteria hierarchically ranks the most informative models, enabling the automatic and principled selection of the model with the strongest support in relation to the time series data. Specifically, we show that AIC scores place each candidate model in the strong support, weak support or no support category. The method correctly identifies several canonical dynamical systems, including an SEIR (susceptibleexposed-infectious-recovered) disease model and the Lorenz equations, giving the correct dynamical system as the only candidate model with strong support.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/7VLCFMEZ/Mangan et al. - 2017 - Model selection for dynamical systems via sparse r.pdf}
}

@article{manganModelSelectionDynamical2017a,
  title = {Model Selection for Dynamical Systems via Sparse Regression and Information Criteria},
  author = {Mangan, N. M. and Kutz, J. N. and Brunton, S. L. and Proctor, J. L.},
  year = {2017},
  month = aug,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {473},
  number = {2204},
  pages = {20170009},
  publisher = {Royal Society},
  doi = {10.1098/rspa.2017.0009},
  urldate = {2024-02-01},
  abstract = {We develop an algorithm for model selection which allows for the consideration of a combinatorially large number of candidate models governing a dynamical system. The innovation circumvents a disadvantage of standard model selection which typically limits the number of candidate models considered due to the intractability of computing information criteria. Using a recently developed sparse identification of nonlinear dynamics algorithm, the sub-selection of candidate models near the Pareto frontier allows feasible computation of Akaike information criteria (AIC) or Bayes information criteria scores for the remaining candidate models. The information criteria hierarchically ranks the most informative models, enabling the automatic and principled selection of the model with the strongest support in relation to the time-series data. Specifically, we show that AIC scores place each candidate model in the strong support, weak support or no support category. The method correctly recovers several canonical dynamical systems, including a susceptible-exposed-infectious-recovered disease model, Burgers' equation and the Lorenz equations, identifying the correct dynamical system as the only candidate model with strong support.},
  keywords = {data-driven discovery,information criteria,model selection,nonlinear dynamics,sparse regression},
  file = {/home/andonis/Zotero/storage/9P4CNVK4/Mangan et al. - 2017 - Model selection for dynamical systems via sparse r.pdf}
}

@article{manleyHighdensityMappingSinglemolecule2008,
  title = {High-Density Mapping of Single-Molecule Trajectories with Photoactivated Localization Microscopy},
  author = {Manley, Suliana and Gillette, Jennifer M. and Patterson, George H. and Shroff, Hari and Hess, Harald F. and Betzig, Eric and {Lippincott-Schwartz}, Jennifer},
  year = {2008},
  month = feb,
  journal = {Nature Methods},
  volume = {5},
  number = {2},
  pages = {155--157},
  issn = {1548-7105},
  doi = {10.1038/nmeth.1176},
  abstract = {We combined photoactivated localization microscopy (PALM) with live-cell single-particle tracking to create a new method termed sptPALM. We created spatially resolved maps of single-molecule motions by imaging the membrane proteins Gag and VSVG, and obtained several orders of magnitude more trajectories per cell than traditional single-particle tracking enables. By probing distinct subsets of molecules, sptPALM can provide insight into the origins of spatial and temporal heterogeneities in membranes.},
  langid = {english},
  pmid = {18193054},
  keywords = {Animals,Chlorocebus aethiops,COS Cells,Image Enhancement,Membrane Proteins,Microscopy Fluorescence},
  file = {/home/andonis/Zotero/storage/53IPUVVQ/Manley et al. - 2008 - High-density mapping of single-molecule trajectories with photoactivated localization microscopy.pdf}
}

@misc{mathpatiDiscoveringStochasticPartial2023,
  title = {Discovering Stochastic Partial Differential Equations from Limited Data Using Variational {{Bayes}} Inference},
  author = {Mathpati, Yogesh Chandrakant and Tripura, Tapas and Nayek, Rajdip and Chakraborty, Souvik},
  year = {2023},
  month = jun,
  number = {arXiv:2306.15873},
  eprint = {2306.15873},
  primaryclass = {stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.15873},
  urldate = {2024-11-28},
  abstract = {We propose a novel framework for discovering Stochastic Partial Differential Equations (SPDEs) from data. The proposed approach combines the concepts of stochastic calculus, variational Bayes theory, and sparse learning. We propose the extended Kramers-Moyal expansion to express the drift and diffusion terms of an SPDE in terms of state responses and use Spike-and-Slab priors with sparse learning techniques to efficiently and accurately discover the underlying SPDEs. The proposed approach has been applied to three canonical SPDEs, (a) stochastic heat equation, (b) stochastic Allen-Cahn equation, and (c) stochastic Nagumo equation. Our results demonstrate that the proposed approach can accurately identify the underlying SPDEs with limited data. This is the first attempt at discovering SPDEs from data, and it has significant implications for various scientific applications, such as climate modeling, financial forecasting, and chemical kinetics.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/ZCS4MXJC/Mathpati et al. - 2023 - Discovering stochastic partial differential equations from limited data using variational Bayes infe.pdf}
}

@article{mathpatiDiscoveringStochasticPartial2024,
  title = {Discovering Stochastic Partial Differential Equations from Limited Data Using Variational {{Bayes}} Inference},
  author = {Mathpati, Yogesh Chandrakant and Tripura, Tapas and Nayek, Rajdip and Chakraborty, Souvik},
  year = {2024},
  month = jan,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {418},
  pages = {116512},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2023.116512},
  urldate = {2024-05-13},
  abstract = {We propose a novel framework for discovering Stochastic Partial Differential Equations (SPDEs) from data. The proposed approach combines the concepts of stochastic calculus, variational Bayes theory, and sparse learning. We propose the extended Kramers--Moyal expansion to express the drift and diffusion terms of an SPDE in terms of state responses and use Spike-and-Slab priors with sparse learning techniques to efficiently and accurately discover the underlying SPDEs. The proposed approach has been applied to three canonical SPDEs, (a) stochastic heat equation, (b) stochastic Allen--Cahn equation, and (c) stochastic Nagumo equation. Our results demonstrate that the proposed approach can accurately identify the underlying SPDEs with limited data. This is the first attempt at discovering SPDEs from data, and it has significant implications for various scientific applications, such as climate modeling, financial forecasting, and chemical kinetics.},
  keywords = {Bayesian model discovery,Equation discovery,Probabilistic machine learning,Stochastic calculus,Stochastic partial differential equation},
  file = {/home/andonis/Zotero/storage/K65Q3XPC/Mathpati et al. - 2024 - Discovering stochastic partial differential equati.pdf;/home/andonis/Zotero/storage/XISRX8B5/S0045782523006369.html}
}

@article{mattinglyMaximizingInformationLearned2018,
  title = {Maximizing the Information Learned from Finite Data Selects a Simple Model},
  author = {Mattingly, Henry H. and Transtrum, Mark K. and Abbott, Michael C. and Machta, Benjamin B.},
  year = {2018},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {8},
  pages = {1760--1765},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1715306115},
  urldate = {2022-11-15},
  abstract = {Significance             Most physical theories are effective theories, descriptions at the scale visible to our experiments which ignore microscopic details. Seeking general ways to motivate such theories, we find an information theory perspective: If we select the model which can learn as much information as possible from the data, then we are naturally led to a simpler model, by a path independent of concerns about overfitting. This is encoded as a Bayesian prior which is nonzero only on a subspace of the original parameter space. We differ from earlier prior selection work by not considering an infinite quantity of data. Having finite data is always a limit on the resolution of an experiment, and in our framework this selects how complicated a theory is appropriate.           ,              We use the language of uninformative Bayesian prior choice to study the selection of appropriately simple effective models. We advocate for the prior which maximizes the mutual information between parameters and predictions, learning as much as possible from limited data. When many parameters are poorly constrained by the available data, we find that this prior puts weight only on boundaries of the parameter space. Thus, it selects a lower-dimensional effective theory in a principled way, ignoring irrelevant parameter directions. In the limit where there are sufficient data to tightly constrain any number of parameters, this reduces to the Jeffreys prior. However, we argue that this limit is pathological when applied to the hyperribbon parameter manifolds generic in science, because it leads to dramatic dependence on effects invisible to experiment.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/3ESX9Y4C/Mattingly et al. - 2018 - Maximizing the information learned from finite dat.pdf;/home/andonis/Zotero/storage/INW96FAB/pnas.201715306si.pdf}
}

@misc{mccabeMultiplePhysicsPretraining2023,
  title = {Multiple {{Physics Pretraining}} for {{Physical Surrogate Models}}},
  author = {McCabe, Michael and Blancard, Bruno R{\'e}galdo-Saint and Parker, Liam Holden and Ohana, Ruben and Cranmer, Miles and Bietti, Alberto and Eickenberg, Michael and Golkar, Siavash and Krawezik, Geraud and Lanusse, Francois and Pettee, Mariel and Tesileanu, Tiberiu and Cho, Kyunghyun and Ho, Shirley},
  year = {2023},
  month = oct,
  number = {arXiv:2310.02994},
  eprint = {2310.02994},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2023-12-19},
  abstract = {We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling. MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks. In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space. We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark. We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning. For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from scratch or finetuning pretrained video foundation models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/andonis/Zotero/storage/IFI6LQ53/McCabe et al. - 2023 - Multiple Physics Pretraining for Physical Surrogat.pdf}
}

@article{messengerWeakSINDyPartial2021,
  title = {Weak {{SINDy}} for Partial Differential Equations},
  author = {Messenger, Daniel A. and Bortz, David M.},
  year = {2021},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {443},
  pages = {110525},
  issn = {00219991},
  doi = {10.1016/j.jcp.2021.110525},
  urldate = {2023-10-30},
  langid = {english},
  file = {/home/andonis/Zotero/storage/P9K2N5Z8/Messenger et Bortz - 2021 - Weak SINDy for partial differential equations.pdf}
}

@inproceedings{mhenniSparseBranchBound2020,
  title = {Sparse {{Branch}} and {{Bound}} for {{Exact Optimization}} of {{L0-Norm Penalized Least Squares}}},
  booktitle = {{{ICASSP}} 2020 - 2020 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Mhenni, Ramzi Ben and Bourguignon, Sebastien and Mongeau, Marcel and Ninin, Jordan and Carfantan, Herve},
  year = {2020},
  month = may,
  pages = {5735--5739},
  publisher = {IEEE},
  address = {Barcelona, Spain},
  doi = {10.1109/ICASSP40776.2020.9053870},
  urldate = {2023-06-07},
  isbn = {978-1-5090-6631-5}
}

@misc{ModelSelectionDynamical,
  title = {Model Selection for Dynamical Systems via Sparse Regression and Information Criteria},
  doi = {10.1098/rspa.2017.0009},
  urldate = {2024-02-01},
  howpublished = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2017.0009},
  langid = {english},
  file = {/home/andonis/Zotero/storage/DM86MLMS/Model selection for dynamical systems via sparse r.pdf;/home/andonis/Zotero/storage/PKQBRN7Y/rspa.2017.html}
}

@misc{mukherjeeConsistentModelSelection2025,
  title = {Consistent Model Selection in the Spiked {{Wigner}} Model via {{AIC-type}} Criteria},
  author = {Mukherjee, Soumendu Sundar},
  year = {2025},
  month = feb,
  number = {arXiv:2307.12982},
  eprint = {2307.12982},
  primaryclass = {math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.12982},
  urldate = {2025-02-10},
  abstract = {Consider the spiked Wigner model {\textbackslash}[ X = {\textbackslash}sum\_\{i = 1\}{\textasciicircum}k {\textbackslash}lambda\_i u\_i u\_i{\textasciicircum}{\textbackslash}top + {\textbackslash}sigma G, {\textbackslash}] where \$G\$ is an \$N {\textbackslash}times N\$ GOE random matrix, and the eigenvalues \${\textbackslash}lambda\_i\$ are all spiked, i.e. above the Baik-Ben Arous-P{\textbackslash}'ech{\textbackslash}'e (BBP) threshold \${\textbackslash}sigma\$. We consider AIC-type model selection criteria of the form {\textbackslash}[ -2 {\textbackslash}, ({\textbackslash}text\{maximised log-likelihood\}) + {\textbackslash}gamma {\textbackslash}, ({\textbackslash}text\{number of parameters\}) {\textbackslash}] for estimating the number \$k\$ of spikes. For \${\textbackslash}gamma {$>$} 2\$, the above criterion is strongly consistent provided \${\textbackslash}lambda\_k {$>$} {\textbackslash}lambda\_\{{\textbackslash}gamma\}\$, where \${\textbackslash}lambda\_\{{\textbackslash}gamma\}\$ is a threshold strictly above the BBP threshold, whereas for \${\textbackslash}gamma {$<$} 2\$, it almost surely overestimates \$k\$. Although AIC (which corresponds to \${\textbackslash}gamma = 2\$) is not strongly consistent, we show that taking \${\textbackslash}gamma = 2 + {\textbackslash}delta\_N\$, where \${\textbackslash}delta\_N {\textbackslash}to 0\$ and \${\textbackslash}delta\_N {\textbackslash}gg N{\textasciicircum}\{-2/3\}\$, results in a weakly consistent estimator of \$k\$. We further show that a soft minimiser of AIC, where one chooses the least complex model whose AIC score is close to the minimum AIC score, is strongly consistent. Based on a spiked (generalised) Wigner representation, we also develop similar model selection criteria for consistently estimating the number of communities in a balanced stochastic block model under some sparsity restrictions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Information Theory,Mathematics - Information Theory,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Methodology,Statistics - Statistics Theory},
  file = {/home/andonis/Zotero/storage/QLG6PC9W/Mukherjee - 2025 - Consistent model selection in the spiked Wigner model via AIC-type criteria.pdf}
}

@article{myungModelSelectionNormalized,
  title = {Model {{Selection}} by {{Normalized Maximum Likelihood}}},
  author = {Myung, Jay I and Navarro, Daniel J and Pitt, Mark A},
  pages = {26},
  abstract = {The Minimum Description Length (MDL) principle is an information theoretic approach to inductive inference that originated in algorithmic coding theory. In this approach, data are viewed as codes to be compressed by the model. From this perspective, models are compared on their ability to compress a data set by extracting useful information in the data apart from random noise. The goal of model selection is to identify the model, from a set of candidate models, that permits the shortest description length (code) of the data. Since Rissanen originally formalized the problem using the crude `two-part code' MDL method in the 1970s, many significant strides have been made, especially in the 1990s, with the culmination of the development of the refined `universal code' MDL method, dubbed Normalized Maximum Likelihood (NML). It represents an elegant solution to the model selection problem. The present paper provides a tutorial review on these latest developments with a special focus on NML. An application example of NML in cognitive modeling is also provided.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/LQ2AMJ8I/Myung et al. - Model Selection by Normalized Maximum Likelihood.pdf}
}

@book{nagaharaSparsityMethodsSystems2020,
  title = {Sparsity {{Methods}} for {{Systems}} and {{Control}}},
  author = {Nagahara, Masaaki},
  year = {2020},
  month = sep,
  abstract = {The method of sparsity has been attracting a lot of attention in the fields related not only to signal processing, machine learning, and statistics, but also systems and control. The method is known as compressed sensing, compressive sampling, sparse representation, or sparse modeling. More recently, the sparsity method has been applied to systems and control to design resource-aware control systems. This book gives a comprehensive guide to sparsity methods for systems and control, from standard sparsity methods in finite-dimensional vector spaces (Part I) to optimal control methods in infinite-dimensional function spaces (Part II). The primary objective of this book is to show how to use sparsity methods for several engineering problems. For this, the author provides MATLAB programs by which the reader can try sparsity methods for themselves. Readers will obtain a deep understanding of sparsity methods by running these MATLAB programs. Sparsity Methods for Systems and Control is suitable for graduate level university courses, though it should also be comprehendible to undergraduate students who have a basic knowledge of linear algebra and elementary calculus. Also, especially part II of the book should appeal to professional researchers and engineers who are interested in applying sparsity methods to systems and control.},
  file = {/home/andonis/Zotero/storage/T8ZD6VQP/Nagahara - 2020 - Sparsity Methods for Systems and Control.pdf}
}

@article{needellUniformUncertaintyPrinciple2009,
  title = {Uniform {{Uncertainty Principle}} and {{Signal Recovery}} via~{{Regularized Orthogonal Matching Pursuit}}},
  author = {Needell, Deanna and Vershynin, Roman},
  year = {2009},
  month = jun,
  journal = {Foundations of Computational Mathematics},
  volume = {9},
  number = {3},
  pages = {317--334},
  issn = {1615-3383},
  doi = {10.1007/s10208-008-9031-3},
  urldate = {2024-10-10},
  abstract = {This paper seeks to bridge the two major algorithmic approaches to sparse signal recovery from an incomplete set of linear measurements---L1-minimization methods and iterative methods (Matching Pursuits). We find a simple regularized version of Orthogonal Matching Pursuit (ROMP) which has advantages of both approaches: the speed and transparency of OMP and the strong uniform guarantees of L1-minimization. Our algorithm, ROMP, reconstructs a sparse signal in a number of iterations linear in the sparsity, and the reconstruction is exact provided the linear measurements satisfy the uniform uncertainty principle.},
  langid = {english},
  keywords = {41A46,65T50,68W20,Basis pursuit,Compressed sensing,Orthogonal matching pursuit,Restricted isometry condition,Signal recovery,Signal recovery algorithms,Sparse approximation,Uncertainty principle},
  file = {/home/andonis/Zotero/storage/AGNHX27Z/Needell et Vershynin - 2009 - Uniform Uncertainty Principle and Signal Recovery via Regularized Orthogonal Matching Pursuit.pdf}
}

@article{needellUniformUncertaintyPrinciple2009a,
  title = {Uniform {{Uncertainty Principle}} and {{Signal Recovery}} via~{{Regularized Orthogonal Matching Pursuit}}},
  author = {Needell, Deanna and Vershynin, Roman},
  year = {2009},
  month = jun,
  journal = {Foundations of Computational Mathematics},
  volume = {9},
  number = {3},
  pages = {317--334},
  issn = {1615-3383},
  doi = {10.1007/s10208-008-9031-3},
  urldate = {2024-10-10},
  abstract = {This paper seeks to bridge the two major algorithmic approaches to sparse signal recovery from an incomplete set of linear measurements---L1-minimization methods and iterative methods (Matching Pursuits). We find a simple regularized version of Orthogonal Matching Pursuit (ROMP) which has advantages of both approaches: the speed and transparency of OMP and the strong uniform guarantees of L1-minimization. Our algorithm, ROMP, reconstructs a sparse signal in a number of iterations linear in the sparsity, and the reconstruction is exact provided the linear measurements satisfy the uniform uncertainty principle.},
  langid = {english},
  keywords = {41A46,65T50,68W20,Basis pursuit,Compressed sensing,Orthogonal matching pursuit,Restricted isometry condition,Signal recovery,Signal recovery algorithms,Sparse approximation,Uncertainty principle},
  file = {/home/andonis/Zotero/storage/2TFHLYIB/Needell et Vershynin - 2009 - Uniform Uncertainty Principle and Signal Recovery via Regularized Orthogonal Matching Pursuit.pdf}
}

@misc{NonlinearStochasticModelling,
  title = {Nonlinear Stochastic Modelling with {{Langevin}} Regression},
  doi = {10.1098/rspa.2021.0092},
  urldate = {2023-10-02},
  howpublished = {https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2021.0092},
  langid = {english},
  file = {/home/andonis/Zotero/storage/YFQQ94ME/Nonlinear stochastic modelling with Langevin regre.pdf;/home/andonis/Zotero/storage/4I97FCH7/rspa.2021.html}
}

@article{palacciLivingCrystalsLightActivated2013,
  title = {Living {{Crystals}} of {{Light-Activated Colloidal Surfers}}},
  author = {Palacci, Jeremie and Sacanna, Stefano and Steinberg, Asher Preska and Pine, David J. and Chaikin, Paul M.},
  year = {2013},
  month = feb,
  journal = {Science},
  volume = {339},
  number = {6122},
  pages = {936--940},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1230020},
  urldate = {2024-09-19},
  abstract = {Spontaneous formation of colonies of bacteria or flocks of birds are examples of self-organization in active living matter. Here, we demonstrate a form of self-organization from nonequilibrium driving forces in a suspension of synthetic photoactivated colloidal particles. They lead to two-dimensional "living crystals," which form, break, explode, and re-form elsewhere. The dynamic assembly results from a competition between self-propulsion of particles and an attractive interaction induced respectively by osmotic and phoretic effects and activated by light. We measured a transition from normal to giant-number fluctuations. Our experiments are quantitatively described by simple numerical simulations. We show that the existence of the living crystals is intrinsically related to the out-of-equilibrium collisions of the self-propelled particles.}
}

@inproceedings{patiOrthogonalMatchingPursuit1993,
  title = {Orthogonal Matching Pursuit: Recursive Function Approximation with Applications to Wavelet Decomposition},
  shorttitle = {Orthogonal Matching Pursuit},
  booktitle = {Proceedings of 27th {{Asilomar Conference}} on {{Signals}}, {{Systems}} and {{Computers}}},
  author = {Pati, Y.C. and Rezaiifar, R. and Krishnaprasad, P.S.},
  year = {1993},
  pages = {40--44},
  publisher = {IEEE Comput. Soc. Press},
  address = {Pacific Grove, CA, USA},
  doi = {10.1109/ACSSC.1993.342465},
  urldate = {2023-06-07},
  isbn = {978-0-8186-4120-6},
  file = {/home/andonis/Zotero/storage/4HF39P7P/Pati et al. - 1993 - Orthogonal matching pursuit recursive function ap.pdf}
}

@article{penlandPredictionNino31993,
  title = {Prediction of {{Ni{\~n}o}} 3 {{Sea Surface Temperatures Using Linear Inverse Modeling}}},
  author = {Penland, C{\'e}cile and Magorian, Theresa},
  year = {1993},
  month = jun,
  journal = {Journal of Climate},
  volume = {6},
  number = {6},
  pages = {1067--1076},
  publisher = {American Meteorological Society},
  issn = {0894-8755, 1520-0442},
  doi = {10.1175/1520-0442(1993)006<1067:PONSST>2.0.CO;2},
  urldate = {2024-09-19},
  abstract = {Linear inverse modeling is used to predict sea surface temperatures (SSTS) in the Ni{\~n}o 3 region. Predictors in three geographical locations are used: the tropical Pacific Ocean, the tropical Pacific and Indian oceans, and the global tropical oceans. Predictions did not depend crucially on any of these three domains, and evidence was found to support the assumption that linear dynamics dominates most of the record. The prediction model performs better when SST anomalies are rapidly evolving than during warm events when large anomalies persist. The rms prediction error at a lead time of 9 months is about half a degree Celsius.},
  chapter = {Journal of Climate},
  langid = {english},
  file = {/home/andonis/Zotero/storage/UKRPM3UY/Penland et Magorian - 1993 - Prediction of Niño 3 Sea Surface Temperatures Using Linear Inverse Modeling.pdf}
}

@article{preislerModelingAnimalMovements2004,
  title = {Modeling Animal Movements Using Stochastic Differential Equations},
  author = {Preisler, Haiganoush K. and Ager, Alan A. and Johnson, Bruce K. and Kie, John G.},
  year = {2004},
  month = nov,
  journal = {Environmetrics},
  volume = {15},
  number = {7},
  pages = {643--657},
  issn = {1180-4009, 1099-095X},
  doi = {10.1002/env.636},
  urldate = {2024-09-03},
  abstract = {Abstract             We describe the use of bivariate stochastic differential equations (SDE) for modeling movements of 216 radio-collared female Rocky Mountain elk at the Starkey Experimental Forest and Range in northeastern Oregon. Spatially and temporally explicit vector fields were estimated using approximating difference equations and nonparametric regression techniques. Estimated vector fields of movement were mapped onto the project area at selected times of the day to examine spatial patterns of movement in relation to topography. Using the concept of a potential function, we were able to study the influence of roads and grassland foraging areas on elk movements. Doing so we identified broad spatial patterns of elk movements and showed the time dependent effects of habitat features within the habitat mosaic at Starkey. Our analyses quantify the cycles of movements in spring and summer in terms of attraction or repulsion to specific habitat features, and illustrate the magnitude, timing and direction of these movements. An extensive list of references is included. Published in 2004 by John Wiley \& Sons, Ltd.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@misc{PublisherCorrectionAutonomous,
  title = {Publisher {{Correction}}: {{Autonomous}} Inference of Complex Network Dynamics from Incomplete and Noisy Data {\textbar} {{Nature Computational Science}}},
  urldate = {2023-10-12},
  howpublished = {https://www.nature.com/articles/s43588-022-00255-8},
  file = {/home/andonis/Zotero/storage/DI4HF85S/s43588-022-00255-8.html}
}

@article{ragwitzIndispensableFiniteTime2001,
  title = {Indispensable {{Finite Time Corrections}} for {{Fokker-Planck Equations}} from {{Time Series Data}}},
  author = {Ragwitz, Mario and Kantz, Holger},
  year = {2001},
  month = dec,
  journal = {Physical Review Letters},
  volume = {87},
  number = {25},
  pages = {254501},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.87.254501},
  urldate = {2024-09-19},
  abstract = {The reconstruction of Fokker-Planck equations from observed time series data suffers strongly from finite sampling rates. We show that previously published results are degraded considerably by such effects. We present correction terms which yield a robust estimation of the diffusion terms, together with a novel method for one-dimensional problems. We apply these methods to time series data of local surface wind velocities, where the dependence of the diffusion constant on the state variable shows a different behavior than previously suggested.}
}

@article{raissiPhysicsinformedNeuralNetworks2019,
  title = {Physics-Informed Neural Networks: {{A}} Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations},
  shorttitle = {Physics-Informed Neural Networks},
  author = {Raissi, M. and Perdikaris, P. and Karniadakis, G. E.},
  year = {2019},
  month = feb,
  journal = {Journal of Computational Physics},
  volume = {378},
  pages = {686--707},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2018.10.045},
  urldate = {2024-09-12},
  abstract = {We introduce physics-informed neural networks -- neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge--Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction--diffusion systems, and the propagation of nonlinear shallow-water waves.},
  keywords = {Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge-Kutta methods},
  file = {/home/andonis/Zotero/storage/52PTF5NA/S0021999118307125.html}
}

@book{riskenFokkerPlanckEquationMethods1996,
  title = {The {{Fokker-Planck}} Equation: Methods of Solution and Applications},
  shorttitle = {The {{Fokker-Planck}} Equation},
  author = {Risken, H.},
  year = {1996},
  series = {Springer Series in Synergetics},
  edition = {2nd ed},
  number = {v. 18},
  publisher = {Springer-Verlag},
  address = {New York},
  isbn = {978-3-540-61530-9},
  langid = {english},
  lccn = {QC20.7.D5 R57 1996},
  keywords = {Fokker-Planck equation},
  file = {/home/andonis/Zotero/storage/R4FLTWXZ/Risken - 1996 - The Fokker-Planck equation methods of solution an.pdf}
}

@book{riskenFokkerPlanckEquationMethods1996a,
  title = {The {{Fokker-Planck Equation}}: {{Methods}} of {{Solution}} and {{Applications}}},
  shorttitle = {The {{Fokker-Planck Equation}}},
  author = {Risken, Hannes},
  editor = {Haken, Hermann},
  year = {1996},
  series = {Springer {{Series}} in {{Synergetics}}},
  volume = {18},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-61544-3},
  urldate = {2023-05-31},
  isbn = {978-3-540-61530-9 978-3-642-61544-3},
  langid = {english},
  keywords = {computer simulation,correlation,differential equation,diffusion,eigenvalue,numerical method,partial differential equation,Potential,probability,probability theory,Random variable,statistics},
  file = {/home/andonis/Zotero/storage/3VI5UVC7/Risken - 1996 - The Fokker-Planck Equation Methods of Solution an.pdf}
}

@book{riskenFokkerPlanckEquationMethods1996b,
  title = {The {{Fokker-Planck Equation}}: {{Methods}} of {{Solution}} and {{Applications}}},
  shorttitle = {The {{Fokker-Planck Equation}}},
  author = {Risken, Hannes},
  editor = {Haken, Hermann},
  year = {1996},
  series = {Springer {{Series}} in {{Synergetics}}},
  volume = {18},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-61544-3},
  urldate = {2023-05-31},
  isbn = {978-3-540-61530-9 978-3-642-61544-3},
  langid = {english},
  keywords = {computer simulation,correlation,differential equation,diffusion,eigenvalue,numerical method,partial differential equation,Potential,probability,probability theory,Random variable,statistics}
}

@incollection{riskenFokkerPlanckEquationSeveral1996,
  title = {Fokker-{{Planck Equation}} for {{Several Variables}}; {{Methods}} of {{Solution}}},
  booktitle = {The {{Fokker-Planck Equation}}: {{Methods}} of {{Solution}} and {{Applications}}},
  author = {Risken, Hannes},
  editor = {Risken, Hannes},
  year = {1996},
  series = {Springer {{Series}} in {{Synergetics}}},
  pages = {133--162},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-61544-3_6},
  urldate = {2023-05-31},
  abstract = {In this chapter we discuss methods of solution for the Fokker-Planck equation (4.94a, 95) for time-independent drift and diffusion coefficients, i.e., for 6.1\$\${\textbackslash}partial W/{\textbackslash}partial t = \{L\_\{FP\}\}W = {\textbackslash}partial \{S\_i\}/{\textbackslash}partial \{x\_i\},\$\$6.2\$\$\{L\_\{FP\}\} =  - {\textbackslash}frac\{{\textbackslash}partial \}\{\{{\textbackslash}partial \{x\_i\}\}\}\{D\_i\}({\textbackslash}\{ x{\textbackslash}\} ) + {\textbackslash}frac\{\{\{{\textbackslash}partial {\textasciicircum}2\}\}\}\{\{{\textbackslash}partial \{x\_i\}{\textbackslash}partial \{x\_j\}\}\}\{D\_\{ij\}\}({\textbackslash}\{ x{\textbackslash}\} ).\$\$(With the exception of Sect. 6.6.5 the summation convention for Latin indices is used in this chapter.)},
  isbn = {978-3-642-61544-3},
  langid = {english},
  keywords = {Detailed Balance,Diffusion Matrix,Eigenfunction Expansion,Summation Convention,Time Reversal},
  file = {/home/andonis/Zotero/storage/9CWL49TA/Risken - 1996 - Fokker-Planck Equation for Several Variables; Meth.pdf}
}

@article{rissanenStochasticComplexity1987,
  title = {Stochastic {{Complexity}}},
  author = {Rissanen, Jorma},
  year = {1987},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {49},
  number = {3},
  pages = {223--239},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1987.tb01694.x},
  urldate = {2024-05-21},
  abstract = {It is argued that all the useful information in observed data that can be extracted with a selected class of modeled distributions, will be obtained if we calculate the stochastic complexity, defined to be the shortest description length of the data. The same quantity also determines the greatest lower bound for prediction errors when the data are sequentially predicted. An abstract definition of stochastic complexity is given along with two fundamental theorems which justify the notion. Further, three explicit model selection criteria to approximate the stochastic complexity are described and the associated optimal models are interpreted to define asymptotically sufficient statistics for the data.},
  copyright = {{\copyright} 1987 Royal Statistical Society},
  langid = {english},
  keywords = {minimum code length,model selection criteria,prior knowledge}
}

@article{rissanenStochasticComplexity1987a,
  title = {Stochastic {{Complexity}}},
  author = {Rissanen, Jorma},
  year = {1987},
  month = jul,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {49},
  number = {3},
  pages = {223--239},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.2517-6161.1987.tb01694.x},
  urldate = {2024-05-21},
  abstract = {SUMMARY             It is argued that all the useful information in observed data that can be extracted with a selected class of modeled distributions, will be obtained if we calculate the stochastic complexity, defined to be the shortest description length of the data. The same quantity also determines the greatest lower bound for prediction errors when the data are sequentially predicted. An abstract definition of stochastic complexity is given along with two fundamental theorems which justify the notion. Further, three explicit model selection criteria to approximate the stochastic complexity are described and the associated optimal models are interpreted to define asymptotically sufficient statistics for the data.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english}
}

@article{schmidtDistillingFreeFormNatural2009,
  title = {Distilling {{Free-Form Natural Laws}} from {{Experimental Data}}},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2009},
  month = apr,
  journal = {Science},
  volume = {324},
  number = {5923},
  pages = {81--85},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1165893},
  urldate = {2022-11-29},
  abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ``alphabet'' used to describe those systems.},
  langid = {english}
}

@article{schmidtDistillingFreeFormNatural2009a,
  title = {Distilling {{Free-Form Natural Laws}} from {{Experimental Data}}},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2009},
  month = apr,
  journal = {Science},
  volume = {324},
  number = {5923},
  pages = {81--85},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.1165893},
  urldate = {2022-11-29},
  abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ``alphabet'' used to describe those systems.}
}

@article{schmidtDistillingFreeFormNatural2009b,
  title = {Distilling {{Free-Form Natural Laws}} from {{Experimental Data}}},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2009},
  month = apr,
  journal = {Science},
  volume = {324},
  number = {5923},
  pages = {81--85},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.1165893},
  urldate = {2023-05-16},
  abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the ``alphabet'' used to describe those systems.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/Q9EVJDH2/Schmidt et Lipson - 2009 - Distilling Free-Form Natural Laws from Experimenta.pdf}
}

@misc{schmittZyxinAllYou2023,
  title = {Zyxin Is All You Need: Machine Learning Adherent Cell Mechanics},
  shorttitle = {Zyxin Is All You Need},
  author = {Schmitt, Matthew S. and Colen, Jonathan and Sala, Stefano and Devany, John and Seetharaman, Shailaja and Gardel, Margaret L. and Oakes, Patrick W. and Vitelli, Vincenzo},
  year = {2023},
  month = feb,
  number = {arXiv:2303.00176},
  eprint = {2303.00176},
  primaryclass = {cond-mat, physics:physics},
  publisher = {arXiv},
  urldate = {2023-12-20},
  abstract = {Cellular form and function emerge from complex mechanochemical systems within the cytoplasm. No systematic strategy currently exists to infer large-scale physical properties of a cell from its many molecular components. This is a significant obstacle to understanding biophysical processes such as cell adhesion and migration. Here, we develop a data-driven biophysical modeling approach to learn the mechanical behavior of adherent cells. We first train neural networks to predict forces generated by adherent cells from images of cytoskeletal proteins. Strikingly, experimental images of a single focal adhesion protein, such as zyxin, are sufficient to predict forces and generalize to unseen biological regimes. This protein field alone contains enough information to yield accurate predictions even if forces themselves are generated by many interacting proteins. We next develop two approaches -- one explicitly constrained by physics, the other more agnostic -- that help construct data-driven continuum models of cellular forces using this single focal adhesion field. Both strategies consistently reveal that cellular forces are encoded by two different length scales in adhesion protein distributions. Beyond adherent cell mechanics, our work serves as a case study for how to integrate neural networks in the construction of predictive phenomenological models in cell biology, even when little knowledge of the underlying microscopic mechanisms exist.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Soft Condensed Matter,Physics - Biological Physics},
  file = {/home/andonis/Zotero/storage/FTGNDDYI/Schmitt et al. - 2023 - Zyxin is all you need machine learning adherent c.pdf}
}

@article{schwarzEstimatingDimensionModel1978,
  title = {Estimating the {{Dimension}} of a {{Model}}},
  author = {Schwarz, Gideon},
  year = {1978},
  journal = {The Annals of Statistics},
  volume = {6},
  number = {2},
  eprint = {2958889},
  eprinttype = {jstor},
  pages = {461--464},
  publisher = {Institute of Mathematical Statistics},
  issn = {0090-5364},
  urldate = {2024-09-02},
  abstract = {The problem of selecting one of a number of models of different dimensions is treated by finding its Bayes solution, and evaluating the leading terms of its asymptotic expansion. These terms are a valid large-sample criterion beyond the Bayesian context, since they do not depend on the a priori distribution.},
  file = {/home/andonis/Téléchargements/1176344136.pdf}
}

@article{searaEntropyProductionRate2018,
  title = {Entropy Production Rate Is Maximized in Non-Contractile Actomyosin},
  author = {Seara, Daniel S. and Yadav, Vikrant and Linsmeier, Ian and Tabatabai, A. Pasha and Oakes, Patrick W. and Tabei, S. M. Ali and Banerjee, Shiladitya and Murrell, Michael P.},
  year = {2018},
  month = nov,
  journal = {Nature Communications},
  volume = {9},
  number = {1},
  pages = {4948},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-018-07413-5},
  urldate = {2024-09-19},
  abstract = {The actin cytoskeleton is an active semi-flexible polymer network whose non-equilibrium properties coordinate both stable and contractile behaviors to maintain or change cell shape. While myosin motors drive the actin cytoskeleton out-of-equilibrium, the role of myosin-driven active stresses in the accumulation and dissipation of mechanical energy is unclear. To investigate this, we synthesize an actomyosin material in vitro whose active stress content can tune the network from stable to contractile. Each increment in activity determines a characteristic spectrum of actin filament fluctuations which is used to calculate the total mechanical work and the production of entropy in the material. We find that the balance of work and entropy does not increase monotonically and the entropy production rate is maximized in the non-contractile, stable state of actomyosin. Our study provides evidence that the origins of entropy production and activity-dependent dissipation relate to disorder in the molecular interactions between actin and myosin.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Biochemistry,Bioinspired materials,Biological physics,Biophysics},
  file = {/home/andonis/Zotero/storage/ZYIBTQRL/Seara et al. - 2018 - Entropy production rate is maximized in non-contractile actomyosin.pdf}
}

@article{sergeDynamicMultipletargetTracing2008,
  title = {Dynamic Multiple-Target Tracing to Probe Spatiotemporal Cartography of Cell Membranes},
  author = {Serg{\'e}, Arnauld and Bertaux, Nicolas and Rigneault, Herv{\'e} and Marguet, Didier},
  year = {2008},
  month = aug,
  journal = {Nature Methods},
  volume = {5},
  number = {8},
  pages = {687--694},
  publisher = {Nature Publishing Group},
  issn = {1548-7105},
  doi = {10.1038/nmeth.1233},
  urldate = {2024-09-20},
  abstract = {Single-particle tracking methods allow detailed analysis of protein movement in cells, but existing tracking algorithms have substantial limitations, particularly at high particle densities. A new software tool overcomes some of these limitations and can be used to track high-density particles in cell membranes. Also in this issue, Jaqaman et al. describe an alternative software tool for high-density single-particle tracking.},
  copyright = {2008 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Bioinformatics,Biological Microscopy,Biological Techniques,Biomedical Engineering/Biotechnology,general,Life Sciences,Proteomics}
}

@article{singhStochasticDynamicsPredatorprey2021,
  title = {Stochastic Dynamics of Predator-Prey Interactions},
  author = {Singh, Abhyudai},
  year = {2021},
  month = aug,
  journal = {PLOS ONE},
  volume = {16},
  number = {8},
  pages = {e0255880},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0255880},
  urldate = {2023-09-05},
  abstract = {The interaction between a consumer (such as, a predator or a parasitoid) and a resource (such as, a prey or a host) forms an integral motif in ecological food webs, and has been modeled since the early 20th century starting from the seminal work of Lotka and Volterra. While the Lotka-Volterra predator-prey model predicts a neutrally stable equilibrium with oscillating population densities, a density-dependent predator attack rate is known to stabilize the equilibrium. Here, we consider a stochastic formulation of the Lotka-Volterra model where the prey's reproduction rate is a random process, and the predator's attack rate depends on both the prey and predator population densities. Analysis shows that increasing the sensitivity of the attack rate to the prey density attenuates the magnitude of stochastic fluctuations in the population densities. In contrast, these fluctuations vary non-monotonically with the sensitivity of the attack rate to the predator density with an optimal level of sensitivity minimizing the magnitude of fluctuations. Interestingly, our systematic study of the predator-prey correlations reveals distinct signatures depending on the form of the density-dependent attack rate. In summary, stochastic dynamics of nonlinear Lotka-Volterra models can be harnessed to infer density-dependent mechanisms regulating predator-prey interactions. Moreover, these mechanisms can have contrasting consequences on population density fluctuations, with predator-dependent attack rates amplifying stochasticity, while prey-dependent attack rates countering to buffer fluctuations.},
  langid = {english},
  keywords = {Eigenvalues,Host-pathogen interactions,Nonlinear dynamics,Population density,Population dynamics,Predation,Predator-prey dynamics,Theoretical ecology},
  file = {/home/andonis/Zotero/storage/LWD8M9VC/Singh - 2021 - Stochastic dynamics of predator-prey interactions.pdf}
}

@article{sorensenParametricInferenceDiffusion2004,
  title = {Parametric {{Inference}} for {{Diffusion Processes Observed}} at {{Discrete Points}} in {{Time}}: A {{Survey}}},
  shorttitle = {Parametric {{Inference}} for {{Diffusion Processes Observed}} at {{Discrete Points}} in {{Time}}},
  author = {S{\o}rensen, Helle},
  year = {2004},
  month = dec,
  journal = {International Statistical Review},
  volume = {72},
  number = {3},
  pages = {337--354},
  issn = {0306-7734, 1751-5823},
  doi = {10.1111/j.1751-5823.2004.tb00241.x},
  urldate = {2024-05-14},
  abstract = {Summary                            This paper is a survey of estimation techniques for stationary and ergodic diffusion processes observed at discrete points in time. The reader is introduced to the following techniques: (i) estimating functions with special emphasis on martingale estimating functions and so-called simple estimating functions; (ii) analytical and numerical approximations of the likelihood function which can in principle be made arbitrarily accurate; (iii) Bayesian analysis and MCMC methods; and (iv) indirect inference and EMM which both introduce auxiliary (but wrong) models and correct for the implied bias by simulation.                        ,              R{\'e}sum{\'e}             Cet article propose un tour d'horizon de techniques d'estimation pour des processus de diffusion stationnaires et ergodiques observ{\'e}s {\`a} des moments discrets. On y pr{\'e}sente les techniques suivantes: (i) fonctions d'estimation, l'accent{\'e}tant mis sur des fonctions faisant intervenir une martingale et sur des fonctions d'estimation dites simples; (ii) approximations analytiques et num{\'e}riques de la fonction de vraisemblance admettant, en principe, une pr{\'e}cision arbitraire; (iii) analyse bayesienne et m{\'e}thodes MCMC; (iv) inf{\'e}rence indirecte et m{\'e}thode EMM, toutes deux introduisant des mod{\`e}les auxiliaires (mais incorrects) et rectifiant, par simulation, le biais r{\'e}sultant.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/HHWJ9EYL/Sørensen - 2004 - Parametric Inference for Diffusion Processes Obser.pdf}
}

@article{soussenBernoulliGaussianDeconvolution2011,
  title = {From {{Bernoulli}}--{{Gaussian Deconvolution}} to {{Sparse Signal Restoration}}},
  author = {Soussen, Charles and Idier, J{\'e}r{\^o}me and Brie, David and Duan, Junbo},
  year = {2011},
  month = oct,
  journal = {IEEE Transactions on Signal Processing},
  volume = {59},
  number = {10},
  pages = {4572--4584},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2011.2160633},
  urldate = {2023-06-07},
  abstract = {Formulated as a least square problem under an {$\ell$}0 constraint, sparse signal restoration is a discrete optimization problem, known to be NP complete. Classical algorithms include, by increasing cost and efficiency, Matching Pursuit (MP), Orthogonal Matching Pursuit (OMP), Orthogonal Least Squares (OLS), stepwise regression algorithms and the exhaustive search. We revisit the Single Most Likely Replacement (SMLR) algorithm, developed in the mid-80's for Bernoulli-Gaussian signal restoration. We show that the formulation of sparse signal restoration as a limit case of Bernoulli-Gaussian signal restoration leads to an {$\ell$}0-penalized least square minimization problem, to which SMLR can be straightforwardly adapted. The resulting algorithm, called Single Best Replacement (SBR), can be interpreted as a forward-backward extension of OLS sharing similarities with stepwise regression algorithms. Some structural properties of SBR are put forward. A fast and stable implementation is proposed. The approach is illustrated on two inverse problems involving highly correlated dictionaries. We show that SBR is very competitive with popular sparse algorithms in terms of trade-off between accuracy and computation time.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/B2PXBWX5/Soussen et al. - 2011 - From Bernoulli–Gaussian Deconvolution to Sparse Si.pdf}
}

@article{soussenBernoulliGaussianDeconvolution2011a,
  title = {From {{Bernoulli}}--{{Gaussian Deconvolution}} to {{Sparse Signal Restoration}}},
  author = {Soussen, Charles and Idier, J{\'e}r{\^o}me and Brie, David and Duan, Junbo},
  year = {2011},
  month = oct,
  journal = {IEEE Transactions on Signal Processing},
  volume = {59},
  number = {10},
  pages = {4572--4584},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2011.2160633},
  urldate = {2023-09-15},
  file = {/home/andonis/Zotero/storage/V446E4GB/Soussen et al. - 2011 - From Bernoulli–Gaussian Deconvolution to Sparse Si.pdf}
}

@article{soussenHomotopyBasedAlgorithms2015,
  title = {Homotopy Based Algorithms for \${\textbackslash}ell\_0\$-Regularized Least-Squares},
  author = {Soussen, Charles and Idier, J{\'e}r{\^o}me and Duan, Junbo and Brie, David},
  year = {2015},
  month = jul,
  journal = {IEEE Transactions on Signal Processing},
  volume = {63},
  number = {13},
  eprint = {1406.4802},
  primaryclass = {cs},
  pages = {3301--3316},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2015.2421476},
  urldate = {2023-05-25},
  abstract = {Sparse signal restoration is usually formulated as the minimization of a quadratic cost function \${\textbackslash}{\textbar}y-Ax{\textbackslash}{\textbar}\_2{\textasciicircum}2\$, where A is a dictionary and x is an unknown sparse vector. It is well-known that imposing an \${\textbackslash}ell\_0\$ constraint leads to an NP-hard minimization problem. The convex relaxation approach has received considerable attention, where the \${\textbackslash}ell\_0\$-norm is replaced by the \${\textbackslash}ell\_1\$-norm. Among the many efficient \${\textbackslash}ell\_1\$ solvers, the homotopy algorithm minimizes \${\textbackslash}{\textbar}y-Ax{\textbackslash}{\textbar}\_2{\textasciicircum}2+{\textbackslash}lambda{\textbackslash}{\textbar}x{\textbackslash}{\textbar}\_1\$ with respect to x for a continuum of \${\textbackslash}lambda\$'s. It is inspired by the piecewise regularity of the \${\textbackslash}ell\_1\$-regularization path, also referred to as the homotopy path. In this paper, we address the minimization problem \${\textbackslash}{\textbar}y-Ax{\textbackslash}{\textbar}\_2{\textasciicircum}2+{\textbackslash}lambda{\textbackslash}{\textbar}x{\textbackslash}{\textbar}\_0\$ for a continuum of \${\textbackslash}lambda\$'s and propose two heuristic search algorithms for \${\textbackslash}ell\_0\$-homotopy. Continuation Single Best Replacement is a forward-backward greedy strategy extending the Single Best Replacement algorithm, previously proposed for \${\textbackslash}ell\_0\$-minimization at a given \${\textbackslash}lambda\$. The adaptive search of the \${\textbackslash}lambda\$-values is inspired by \${\textbackslash}ell\_1\$-homotopy. \${\textbackslash}ell\_0\$ Regularization Path Descent is a more complex algorithm exploiting the structural properties of the \${\textbackslash}ell\_0\$-regularization path, which is piecewise constant with respect to \${\textbackslash}lambda\$. Both algorithms are empirically evaluated for difficult inverse problems involving ill-conditioned dictionaries. Finally, we show that they can be easily coupled with usual methods of model order selection.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/home/andonis/Zotero/storage/CISXTP8N/Soussen et al. - 2015 - Homotopy based algorithms for $ell_0$-regularized.pdf}
}

@article{soussenHomotopyBasedAlgorithms2015a,
  title = {Homotopy {{Based Algorithms}} for \${\textbackslash}ell \_\{{\textbackslash}scriptscriptstyle 0\}\$-{{Regularized Least-Squares}}},
  author = {Soussen, Charles and Idier, Jerome and Duan, Junbo and Brie, David},
  year = {2015},
  month = jul,
  journal = {IEEE Transactions on Signal Processing},
  volume = {63},
  number = {13},
  pages = {3301--3316},
  issn = {1053-587X, 1941-0476},
  doi = {10.1109/TSP.2015.2421476},
  urldate = {2023-06-08},
  file = {/home/andonis/Zotero/storage/37PB6XH2/Soussen et al. - 2015 - Homotopy Based Algorithms for $ell _ scriptscrip.pdf}
}

@article{spagnoloNOISEINDUCEDPHENOMENA2003,
  title = {{{NOISE INDUCED PHENOMENA IN LOTKA-VOLTERRA SYSTEMS}}},
  author = {Spagnolo, B. and Fiasconaro, A. and Valenti, D.},
  year = {2003},
  month = jun,
  journal = {Fluctuation and Noise Letters},
  volume = {03},
  number = {02},
  pages = {L177-L185},
  issn = {0219-4775, 1793-6780},
  doi = {10.1142/S0219477503001245},
  urldate = {2024-02-06},
  abstract = {We study the time evolution of two ecosystems in the presence of external noise and climatic periodical forcing by a generalized Lotka-Volterra (LV) model. In the first ecosystem, composed by two competing species, we find noise induced phenomena such as: (i) quasi deterministic oscillations, (ii) stochastic resonance, (iii) noise delayed extinction and (iv) spatial patterns. In the second ecosystem, composed by three interacting species (one predator and two preys), using a discrete model of the LV equations we find that the time evolution of the spatial patterns is strongly dependent on the initial conditions of the three species.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/NCYNZFMW/Spagnolo et al. - 2003 - NOISE INDUCED PHENOMENA IN LOTKA-VOLTERRA SYSTEMS.pdf}
}

@article{stephensDimensionalityDynamicsBehavior2008,
  title = {Dimensionality and {{Dynamics}} in the {{Behavior}} of {{C}}. Elegans},
  author = {Stephens, Greg J. and {Johnson-Kerner}, Bethany and Bialek, William and Ryu, William S.},
  editor = {Sporns, Olaf},
  year = {2008},
  month = apr,
  journal = {PLoS Computational Biology},
  volume = {4},
  number = {4},
  pages = {e1000028},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000028},
  urldate = {2024-02-06},
  abstract = {A major challenge in analyzing animal behavior is to discover some underlying simplicity in complex motor actions. Here, we show that the space of shapes adopted by the nematode Caenorhabditis elegans is low dimensional, with just four dimensions accounting for 95\% of the shape variance. These dimensions provide a quantitative description of worm behavior, and we partially reconstruct ``equations of motion'' for the dynamics in this space. These dynamics have multiple attractors, and we find that the worm visits these in a rapid and almost completely deterministic response to weak thermal stimuli. Stimulus-dependent correlations among the different modes suggest that one can generate more reliable behaviors by synchronizing stimuli to the state of the worm in shape space. We confirm this prediction, effectively ``steering'' the worm in real time.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/85A5U644/Stephens et al. - 2008 - Dimensionality and Dynamics in the Behavior of C. .pdf}
}

@article{stephensDimensionalityDynamicsBehavior2008a,
  title = {Dimensionality and {{Dynamics}} in the {{Behavior}} of {{C}}. Elegans},
  author = {Stephens, Greg J. and {Johnson-Kerner}, Bethany and Bialek, William and Ryu, William S.},
  editor = {Sporns, Olaf},
  year = {2008},
  month = apr,
  journal = {PLoS Computational Biology},
  volume = {4},
  number = {4},
  pages = {e1000028},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1000028},
  urldate = {2024-09-19},
  abstract = {A major challenge in analyzing animal behavior is to discover some underlying simplicity in complex motor actions. Here, we show that the space of shapes adopted by the nematode Caenorhabditis elegans is low dimensional, with just four dimensions accounting for 95\% of the shape variance. These dimensions provide a quantitative description of worm behavior, and we partially reconstruct ``equations of motion'' for the dynamics in this space. These dynamics have multiple attractors, and we find that the worm visits these in a rapid and almost completely deterministic response to weak thermal stimuli. Stimulus-dependent correlations among the different modes suggest that one can generate more reliable behaviors by synchronizing stimuli to the state of the worm in shape space. We confirm this prediction, effectively ``steering'' the worm in real time.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/79ECIYGA/Stephens et al. - 2008 - Dimensionality and Dynamics in the Behavior of C. elegans.pdf}
}

@article{tibshiraniRegressionShrinkageSelection1996,
  title = {Regression {{Shrinkage}} and {{Selection Via}} the {{Lasso}}},
  author = {Tibshirani, Robert},
  year = {1996},
  month = jan,
  journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume = {58},
  number = {1},
  pages = {267--288},
  issn = {1369-7412, 1467-9868},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  urldate = {2024-10-10},
  abstract = {SUMMARY             We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
  copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
  langid = {english}
}

@article{troppComputationalMethodsSparse2010,
  title = {Computational {{Methods}} for {{Sparse Solution}} of {{Linear Inverse Problems}}},
  author = {Tropp, Joel A. and Wright, Stephen J.},
  year = {2010},
  month = jun,
  journal = {Proceedings of the IEEE},
  volume = {98},
  number = {6},
  pages = {948--958},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2010.2044010},
  abstract = {The goal of the sparse approximation problem is to approximate a target signal using a linear combination of a few elementary signals drawn from a fixed collection. This paper surveys the major practical algorithms for sparse approximation. Specific attention is paid to computational issues, to the circumstances in which individual methods tend to perform well, and to the theoretical guarantees available. Many fundamental questions in electrical engineering, statistics, and applied mathematics can be posed as sparse approximation problems, making these algorithms versatile and relevant to a plethora of applications.},
  keywords = {Approximation algorithms,Compressed sensing,convex optimization,Dictionaries,Electrical engineering,Inverse problems,Least squares approximation,matching pursuit,Matching pursuit algorithms,Mathematics,Signal processing,Signal processing algorithms,sparse approximation,Statistics},
  file = {/home/andonis/Zotero/storage/SAZY75GS/Tropp et Wright - 2010 - Computational Methods for Sparse Solution of Linea.pdf;/home/andonis/Zotero/storage/5IK7X45P/5456165.html}
}

@article{troppSignalRecoveryRandom2007,
  title = {Signal {{Recovery From Random Measurements Via Orthogonal Matching Pursuit}}},
  author = {Tropp, Joel A. and Gilbert, Anna C.},
  year = {2007},
  month = dec,
  journal = {IEEE Transactions on Information Theory},
  volume = {53},
  number = {12},
  pages = {4655--4666},
  issn = {0018-9448},
  doi = {10.1109/TIT.2007.909108},
  urldate = {2023-06-07},
  file = {/home/andonis/Zotero/storage/VYW529WE/Tropp et Gilbert - 2007 - Signal Recovery From Random Measurements Via Ortho.pdf}
}

@article{unamiStochasticDifferentialEquation2010,
  title = {A Stochastic Differential Equation Model for Assessing Drought and Flood Risks},
  author = {Unami, Koichi and Abagale, Felix Kofi and Yangyuoru, Macarius and Badiul Alam, Abul Hasan M. and {Kranjac-Berisavljevic}, Gordana},
  year = {2010},
  month = jul,
  journal = {Stochastic Environmental Research and Risk Assessment},
  volume = {24},
  number = {5},
  pages = {725--733},
  issn = {1436-3240, 1436-3259},
  doi = {10.1007/s00477-009-0359-2},
  urldate = {2024-09-03},
  copyright = {http://www.springer.com/tdm},
  langid = {english}
}

@article{vandenbergEcologicalModellingApproaches2022,
  title = {Ecological Modelling Approaches for Predicting Emergent Properties in Microbial Communities},
  author = {Van Den Berg, Naomi Iris and Machado, Daniel and Santos, Sophia and Rocha, Isabel and Chac{\'o}n, Jeremy and Harcombe, William and Mitri, Sara and Patil, Kiran R.},
  year = {2022},
  month = may,
  journal = {Nature Ecology \& Evolution},
  volume = {6},
  number = {7},
  pages = {855--865},
  issn = {2397-334X},
  doi = {10.1038/s41559-022-01746-7},
  urldate = {2023-09-13},
  abstract = {Recent studies have brought forward the critical role of emergent properties in shaping microbial communities and the ecosystems they are part of. Emergent properties - patterns or functions that cannot be deduced linearly from the properties of the constituent parts - underlie important ecological characteristics such as resilience, niche expansion, and spatial self-organisation. While it is clear that emergent properties are a consequence of interactions within the community, their non-linear nature makes mathematical modelling imperative for establishing the quantitative link between community structure and function. As the need for conservation and rational modulation of microbial ecosystems is increasingly apparent, so is the consideration of the benefits and limitations of the approaches to model emergent properties. Here we review ecosystem modelling approaches from the viewpoint of emergent properties. We consider the scope, advantages, and limitations of Lotka-Volterra, consumer-resource, trait-based, individual-based, and genome-scale metabolic models. Future efforts in this research area would benefit from capitalising on the complementarity between these approaches towards enabling rational modulation of complex microbial ecosystems.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/TXLD7QCG/Van Den Berg et al. - 2022 - Ecological modelling approaches for predicting eme.pdf}
}

@article{vandenbergEcologicalModellingApproaches2022a,
  title = {Ecological Modelling Approaches for Predicting Emergent Properties in Microbial Communities},
  author = {{van den Berg}, Naomi Iris and Machado, Daniel and Santos, Sophia and Rocha, Isabel and Chac{\'o}n, Jeremy and Harcombe, William and Mitri, Sara and Patil, Kiran R.},
  year = {2022},
  month = jul,
  journal = {Nature Ecology \& Evolution},
  volume = {6},
  number = {7},
  pages = {855--865},
  publisher = {Nature Publishing Group},
  issn = {2397-334X},
  doi = {10.1038/s41559-022-01746-7},
  urldate = {2023-09-13},
  abstract = {Recent studies have brought forward the critical role of emergent properties in shaping microbial communities and the ecosystems of which they are a part. Emergent properties---patterns or functions that cannot be deduced linearly from the properties of the constituent parts---underlie important ecological characteristics such as resilience, niche expansion and spatial self-organization. While it is clear that emergent properties are a consequence of interactions within the community, their non-linear nature makes mathematical modelling imperative for establishing the quantitative link between community structure and function. As the need for conservation and rational modulation of microbial ecosystems is increasingly apparent, so is the consideration of the benefits and limitations of the approaches to model emergent properties. Here we review ecosystem modelling approaches from the viewpoint of emergent properties. We consider the scope, advantages and limitations of Lotka--Volterra, consumer--resource, trait-based, individual-based and genome-scale metabolic models. Future efforts in this research area would benefit from capitalizing on the complementarity between these approaches towards enabling rational modulation of complex microbial ecosystems.},
  copyright = {2022 Springer Nature Limited},
  langid = {english},
  keywords = {Computational biology and bioinformatics,Ecology,Microbiology},
  file = {/home/andonis/Zotero/storage/M6PKIUP8/van den Berg et al. - 2022 - Ecological modelling approaches for predicting eme.pdf}
}

@article{vestergaardOptimalEstimationDiffusion2014,
  title = {Optimal Estimation of Diffusion Coefficients from Single-Particle Trajectories},
  author = {Vestergaard, Christian L. and Blainey, Paul C. and Flyvbjerg, Henrik},
  year = {2014},
  month = feb,
  journal = {Physical Review E},
  volume = {89},
  number = {2},
  pages = {022726},
  issn = {1539-3755, 1550-2376},
  doi = {10.1103/PhysRevE.89.022726},
  urldate = {2023-06-06},
  langid = {english},
  file = {/home/andonis/Zotero/storage/Q5JXYE2G/Vestergaard et al. - 2014 - Optimal estimation of diffusion coefficients from .pdf}
}

@article{vestergaardOptimalEstimationDiffusion2014a,
  title = {Optimal Estimation of Diffusion Coefficients from Single-Particle Trajectories},
  author = {Vestergaard, Christian L. and Blainey, Paul C. and Flyvbjerg, Henrik},
  year = {2014},
  month = feb,
  journal = {Physical Review E},
  volume = {89},
  number = {2},
  pages = {022726},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.89.022726},
  urldate = {2024-09-19},
  abstract = {How does one optimally determine the diffusion coefficient of a diffusing particle from a single-time-lapse recorded trajectory of the particle? We answer this question with an explicit, unbiased, and practically optimal covariance-based estimator (CVE). This estimator is regression-free and is far superior to commonly used methods based on measured mean squared displacements. In experimentally relevant parameter ranges, it also outperforms the analytically intractable and computationally more demanding maximum likelihood estimator (MLE). For the case of diffusion on a flexible and fluctuating substrate, the CVE is biased by substrate motion. However, given some long time series and a substrate under some tension, an extended MLE can separate particle diffusion on the substrate from substrate motion in the laboratory frame. This provides benchmarks that allow removal of bias caused by substrate fluctuations in CVE. The resulting unbiased CVE is optimal also for short time series on a fluctuating substrate. We have applied our estimators to human 8-oxoguanine DNA glycolase proteins diffusing on flow-stretched DNA, a fluctuating substrate, and found that diffusion coefficients are severely overestimated if substrate fluctuations are not accounted for.},
  file = {/home/andonis/Zotero/storage/VAQ8ASHR/Vestergaard et al. - 2014 - Optimal estimation of diffusion coefficients from single-particle trajectories.pdf;/home/andonis/Zotero/storage/3UXYCQCR/PhysRevE.89.html}
}

@article{vriezeModelSelectionPsychological2012,
  title = {Model Selection and Psychological Theory: {{A}} Discussion of the Differences between the {{Akaike}} Information Criterion ({{AIC}}) and the {{Bayesian}} Information Criterion ({{BIC}}).},
  shorttitle = {Model Selection and Psychological Theory},
  author = {Vrieze, Scott I.},
  year = {2012},
  journal = {Psychological Methods},
  volume = {17},
  number = {2},
  pages = {228--243},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/a0027127},
  urldate = {2024-09-09},
  langid = {english},
  file = {/home/andonis/Zotero/storage/QM9ZFLWL/Vrieze - 2012 - Model selection and psychological theory A discussion of the differences between the Akaike informa.pdf}
}

@article{wannerHigherOrderDrift2024,
  title = {On {{Higher Order Drift}} and {{Diffusion Estimates}} for {{Stochastic SINDy}}},
  author = {Wanner, Mathias and Mezi{\'c}, Igor},
  year = {2024},
  month = jun,
  journal = {SIAM Journal on Applied Dynamical Systems},
  volume = {23},
  number = {2},
  pages = {1504--1539},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/23M1567011},
  urldate = {2025-02-12},
  abstract = {.In this paper, we give an in-depth error analysis for surrogate models generated by a variant of the Sparse Identification of Nonlinear Dynamics (SINDy) method. We start with an overview of a variety of nonlinear system identification techniques, namely SINDy, weak-SINDy, and the occupation kernel method. Under the assumption that the dynamics are a finite linear combination of a set of basis functions, these methods establish a linear system to recover coefficients. We illuminate the structural similarities between these techniques and establish a projection property for the weak-SINDy technique. Following the overview, we analyze the error of surrogate models generated by a simplified version of weak-SINDy. In particular, under the assumption of boundedness of a composition operator given by the solution, we show that (i) the surrogate dynamics converges towards the true dynamics and (ii) the solution of the surrogate model is reasonably close to the true solution. Finally, as an application, we discuss the use of a combination of weak-SINDy surrogate modeling and proper orthogonal decomposition (POD) to build a surrogate model for partial differential equations (PDEs).}
}

@misc{wannerNumericalMethodsStochastic2023,
  title = {On {{Numerical Methods}} for {{Stochastic SINDy}}},
  author = {Wanner, Mathias and Mezi{\'c}, Igor},
  year = {2023},
  month = jun,
  number = {arXiv:2306.17814},
  eprint = {2306.17814},
  primaryclass = {cs, math},
  publisher = {arXiv},
  urldate = {2023-11-23},
  abstract = {The Sparse Identification of Nonlinear Dynamics (SINDy) algorithm can be applied to stochastic differential equations to estimate the drift and the diffusion function using data from a realization of the SDE. The SINDy algorithm requires sample data from each of these functions, which is typically estimated numerically from the data of the state. We analyze the performance of the previously proposed estimates for the drift and diffusion function to give bounds on the error for finite data. However, since this algorithm only converges as both the sampling frequency and the length of trajectory go to infinity, obtaining approximations within a certain tolerance may be infeasible. To combat this, we develop estimates with higher orders of accuracy for use in the SINDy framework. For a given sampling frequency, these estimates give more accurate approximations of the drift and diffusion functions, making SINDy a far more feasible system identification method.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {37H99 37M15 60H35 65C40 93E12,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis},
  file = {/home/andonis/Zotero/storage/42IVW7W3/Wanner et Mezić - 2023 - On Numerical Methods for Stochastic SINDy.pdf}
}

@misc{wannerRobustApproximationStochastic2022,
  title = {Robust {{Approximation}} of the {{Stochastic Koopman Operator}}},
  author = {Wanner, Mathias and Mezi{\'c}, Igor},
  year = {2022},
  month = feb,
  number = {arXiv:2011.00078},
  eprint = {2011.00078},
  primaryclass = {math},
  publisher = {arXiv},
  urldate = {2024-03-13},
  abstract = {We analyze the performance of Dynamic Mode Decomposition (DMD)-based approximations of the stochastic Koopman operator for random dynamical systems where either the dynamics or observables are affected by noise. For many DMD algorithms, the presence of noise can introduce a bias in the DMD operator, leading to poor approximations of the dynamics. In particular, methods using time delayed observables, such as Hankel DMD, are biased when the dynamics are random. We introduce a new, robust DMD algorithm that can approximate the stochastic Koopman operator despite the presence of noise. We then demonstrate how this algorithm can be applied to time delayed observables, which allows us to generate a Krylov subspace from a single observable. This allows us to compute a realization of the stochastic Koopman operator using a single observable measured over a single trajectory. We test the performance of the algorithms over several examples.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Mathematics - Dynamical Systems},
  file = {/home/andonis/Zotero/storage/GAFNFGQW/Wanner et Mezić - 2022 - Robust Approximation of the Stochastic Koopman Ope.pdf}
}

@article{WikiKalmanFilter2022,
  title = {Wiki {{Kalman}} Filter},
  year = {2022},
  month = oct,
  journal = {Wikipedia},
  urldate = {2022-11-01},
  abstract = {For statistics and control theory, Kalman filtering, also known as linear quadratic estimation (LQE), is an algorithm that uses a series of measurements observed over time, including statistical noise and other inaccuracies, and produces estimates of unknown variables that tend to be more accurate than those based on a single measurement alone, by estimating a joint probability distribution over the variables for each timeframe. The filter is named after Rudolf E. K{\'a}lm{\'a}n, who was one of the primary developers of its theory. This digital filter is sometimes termed the Stratonovich--Kalman--Bucy filter because it is a special case of a more general, nonlinear filter developed somewhat earlier by the Soviet mathematician Ruslan Stratonovich. In fact, some of the special case linear filter's equations appeared in  papers by Stratonovich that were published before summer 1960, when Kalman met with Stratonovich during a conference in Moscow.Kalman filtering has numerous technological applications. A common application is for guidance, navigation, and control of vehicles, particularly aircraft, spacecraft and ships positioned dynamically. Furthermore, Kalman filtering is a concept much applied in time series analysis used for topics such as signal processing and econometrics. Kalman filtering is also one of the main topics of robotic motion planning and control and can be used for trajectory optimization. Kalman filtering also works for modeling the central nervous system's control of movement. Due to the time delay between issuing motor commands and receiving sensory feedback, the use of Kalman filters provides a realistic model for making estimates of the current state of a motor system and issuing updated commands.The algorithm works by a two-phase process. For the prediction phase, the Kalman filter produces estimates of the current state variables, along with their uncertainties. Once the outcome of the next measurement (necessarily corrupted with some error, including random noise) is observed, these estimates are updated using a weighted average, with more weight being given to estimates with greater certainty. The algorithm is recursive. It can operate in real time, using only the present input measurements and the state calculated previously and its uncertainty matrix; no additional past information is required. Optimality of Kalman filtering assumes that errors have a normal (Gaussian) distribution.  In the words of Rudolf E. K{\'a}lm{\'a}n: "In summary, the following assumptions are made about random processes: Physical random phenomena may be thought of as due to primary random sources exciting dynamic systems. The primary sources are assumed to be independent gaussian random processes with zero mean; the dynamic systems will be linear."  Though regardless of Gaussianity, if the process and measurement covariances are known, the Kalman filter is the best possible linear estimator in the minimum mean-square-error sense.Extensions and generalizations of the method have also been developed, such as the extended Kalman filter and the unscented Kalman filter which work on nonlinear systems. The basis is a hidden Markov model such that the state space of the latent variables is continuous and all latent and observed variables have Gaussian distributions. Kalman filtering has been used successfully in multi-sensor fusion, and distributed sensor networks to develop distributed or consensus Kalman filtering.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1117911450},
  file = {/home/andonis/Zotero/storage/QCLH7A82/Kalman_filter.html}
}

@article{xuProportionalStochasticGeneralized2023,
  title = {Proportional Stochastic Generalized {{Lotka}}--{{Volterra}} Model with an Application to Learning Microbial Community Structures},
  author = {Xu, Libai and Kong, Dehan and Wang, Lidan and Gu, Hong and Kenney, Toby and Xu, Ximing},
  year = {2023},
  month = jul,
  journal = {Applied Mathematics and Computation},
  volume = {448},
  pages = {127932},
  issn = {0096-3003},
  doi = {10.1016/j.amc.2023.127932},
  urldate = {2023-09-13},
  abstract = {Inferring microbial community structure based on temporal metagenomics data is an important goal in microbiome studies. The deterministic generalized Lotka--Volterra (GLV) differential equations~have been commonly used to model the dynamics of microbial taxa. However, these approaches fail to take random environmental fluctuations into account and usually ignore the compositional nature of relative abundance data, which may deteriorate the estimates. In this article, we consider the microbial dynamics in terms of relative abundances by introducing a reference taxon, and propose a new proportional stochastic GLV (pSGLV) differential equation~model, where the random perturbations of Brownian motion in this model can naturally account for the external environmental effects on the microbial community. We establish conditions and show some mathematical properties of the solutions including general existence and uniqueness, stochastic ultimate boundedness, stochastic permanence, the existence of stationary distribution, and ergodicity property. We further develop approximate maximum likelihood estimators (AMLEs) based on discrete observations and systematically investigate the consistency and asymptotic normality of the proposed estimators. At last, numerical simulations support our theoretical findings and our method is demonstrated through an application to the well-known ``moving picture'' temporal microbial dataset.},
  keywords = {Interaction network,Maximum likelihood,Relative abundance,Stochastic differential equation},
  file = {/home/andonis/Zotero/storage/DCJSK9HR/S0096300323001017.html}
}

@misc{xuStochasticGeneralizedLotkaVolterra2020,
  title = {Stochastic {{Generalized Lotka-Volterra Model}} with {{An Application}} to {{Learning Microbial Community Structures}}},
  author = {Xu, Libai and Xu, Ximing and Kong, Dehan and Gu, Hong and Kenney, Toby},
  year = {2020},
  month = sep,
  number = {arXiv:2009.10922},
  eprint = {2009.10922},
  primaryclass = {stat},
  publisher = {arXiv},
  urldate = {2023-09-13},
  abstract = {Inferring microbial community structure based on temporal metagenomics data is an important goal in microbiome studies. The deterministic generalized Lotka-Volterra differential (GLV) equations have been used to model the dynamics of microbial data. However, these approaches fail to take random environmental fluctuations into account, which may negatively impact the estimates. We propose a new stochastic GLV (SGLV) differential equation model, where the random perturbations of Brownian motion in the model can naturally account for the external environmental effects on the microbial community. We establish new conditions and show various mathematical properties of the solutions including general existence and uniqueness, stationary distribution, and ergodicity. We further develop approximate maximum likelihood estimators based on discrete observations and systematically investigate the consistency and asymptotic normality of the proposed estimators. Our method is demonstrated through simulation studies and an application to the well-known "moving picture" temporal microbial dataset.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Statistics - Methodology},
  file = {/home/andonis/Zotero/storage/QAR6LPTM/Xu et al. - 2020 - Stochastic Generalized Lotka-Volterra Model with A.pdf}
}

@techreport{zapien-camposInferringInteractionsMicrobiome2023,
  type = {Preprint},
  title = {Inferring Interactions from Microbiome Data},
  author = {{Zapi{\'e}n-Campos}, Rom{\'a}n and Bansept, Florence and Traulsen, Arne},
  year = {2023},
  month = mar,
  institution = {Ecology},
  doi = {10.1101/2023.03.30.534939},
  urldate = {2023-09-05},
  abstract = {Abstract           Parameter inference of high-dimensional data is challenging and microbiome time series data is no exception. Methods aimed at predicting from point estimates exist, but often even fail to recover the true parameters from simulated data. Computational methods to robustly infer and quantify the uncertainty in model parameters are needed. Here, we propose a computational workflow addressing such challenges -- allowing us to compare mechanistic models and identify the values and the certainty of inferred parameters. This approach allows us to infer which kind of interactions occur in the microbial community. In contrast to point-estimate inference, the distribution for the parameters, our outcome, reflects their uncertainty. To achieve this, we consider as many equations for the statistical moments of the microbiome as parameters. Our inference workflow, which builds upon a mechanistic foundation of microscopic processes, can take into account that commonly metagenomic datasets only provide information on relative abundances and hosts' ensembles. With our framework, we move from qualitative prediction to quantifying the likelihood of certain interaction types in microbiomes.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/WVCN79F9/Zapién-Campos et al. - 2023 - Inferring interactions from microbiome data.pdf}
}

@article{zarate-minanoContinuousWindSpeed2013,
  title = {Continuous Wind Speed Models Based on Stochastic Differential Equations},
  author = {{Z{\'a}rate-Mi{\~n}ano}, Rafael and Anghel, Marian and Milano, Federico},
  year = {2013},
  month = apr,
  journal = {Applied Energy},
  volume = {104},
  pages = {42--49},
  issn = {03062619},
  doi = {10.1016/j.apenergy.2012.10.064},
  urldate = {2024-09-03},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english}
}

@article{zhangEffectiveDynamicsGiven2016,
  title = {Effective Dynamics along given Reaction Coordinates, and Reaction Rate Theory},
  author = {Zhang, Wei and Hartmann, Carsten and Sch{\"u}tte, Christof},
  year = {2016},
  journal = {Faraday Discussions},
  volume = {195},
  pages = {365--394},
  issn = {1359-6640, 1364-5498},
  doi = {10.1039/C6FD00147E},
  urldate = {2022-10-25},
  abstract = {In molecular dynamics and related fields one considers dynamical descriptions of complex systems in full (atomic) detail. In order to reduce the overwhelming complexity of realistic systems (high dimension, large timescale spread, limited computational resources) the projection of the full dynamics onto some reaction coordinates is examined in order to extract statistical information like free energies or reaction rates. In this context, the effective dynamics that is induced by the full dynamics on the reaction coordinate space has attracted considerable attention in the literature. In this article, we contribute to this discussion: we first show that if we start with an ergodic diffusion process whose invariant measure is unique then these properties are inherited by the effective dynamics. Then, we give equations for the effective dynamics, discuss whether the dominant timescales and reaction rates inferred from the effective dynamics are accurate approximations of such quantities for the full dynamics, and compare our findings to results from approaches like Mori--Zwanzig, averaging, or homogenization. Finally, by discussing the algorithmic realization of the effective dynamics, we demonstrate that recent algorithmic techniques like the ``equation-free'' approach and the ``heterogeneous multiscale method'' can be seen as special cases of our approach.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/IDP553UD/Zhang et al. - 2016 - Effective dynamics along given reaction coordinate.pdf}
}

@article{zhengUnifiedFrameworkSparse2019,
  title = {A {{Unified Framework}} for {{Sparse Relaxed Regularized Regression}}: {{SR3}}},
  shorttitle = {A {{Unified Framework}} for {{Sparse Relaxed Regularized Regression}}},
  author = {Zheng, Peng and Askham, Travis and Brunton, Steven L. and Kutz, J. Nathan and Aravkin, Aleksandr Y.},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {1404--1423},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2886528},
  abstract = {Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.},
  keywords = {compressed sensing,Compressed sensing,Convergence,LASSO,Level set,matrix completion,Nonconvex optimization,Optimization,Signal processing algorithms,Sparse matrices,sparse regression,total variation regularization,TV},
  file = {/home/andonis/Zotero/storage/LMWSWCH6/Zheng et al. - 2019 - A Unified Framework for Sparse Relaxed Regularized.pdf;/home/andonis/Zotero/storage/UHJNDJ73/stamp.html}
}

@article{zhengUnifiedFrameworkSparse2019a,
  title = {A {{Unified Framework}} for {{Sparse Relaxed Regularized Regression}}: {{SR3}}},
  shorttitle = {A {{Unified Framework}} for {{Sparse Relaxed Regularized Regression}}},
  author = {Zheng, Peng and Askham, Travis and Brunton, Steven L. and Kutz, J. Nathan and Aravkin, Aleksandr Y.},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {1404--1423},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2886528},
  urldate = {2023-04-26},
  abstract = {Regularized regression problems are ubiquitous in statistical modeling, signal processing, and machine learning. Sparse regression, in particular, has been instrumental in scientific model discovery, including compressed sensing applications, variable selection, and high-dimensional analysis. We propose a broad framework for sparse relaxed regularized regression, called SR3. The key idea is to solve a relaxation of the regularized problem, which has three advantages over the state-of-the-art: 1) solutions of the relaxed problem are superior with respect to errors, false positives, and conditioning; 2) relaxation allows extremely fast algorithms for both convex and nonconvex formulations; and 3) the methods apply to composite regularizers, essential for total variation (TV) as well as sparsity-promoting formulations using tight frames. We demonstrate the advantages of SR3 (computational efficiency, higher accuracy, faster convergence rates, and greater flexibility) across a range of regularized regression problems with synthetic and real data, including applications in compressed sensing, LASSO, matrix completion, TV regularization, and group sparsity. Following standards of reproducible research, we also provide a companion MATLAB package that implements these examples.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/BH5CPCBF/Zheng et al. - 2019 - A Unified Framework for Sparse Relaxed Regularized.pdf}
}

@article{zisisDisentanglingCadherinmediatedCellcell2022,
  title = {Disentangling Cadherin-Mediated Cell-Cell Interactions in Collective Cancer Cell Migration},
  author = {Zisis, Themistoklis and Br{\"u}ckner, David B. and Brandst{\"a}tter, Tom and Siow, Wei Xiong and {d'Alessandro}, Joseph and Vollmar, Angelika M. and Broedersz, Chase P. and Zahler, Stefan},
  year = {2022},
  month = jan,
  journal = {Biophysical Journal},
  volume = {121},
  number = {1},
  pages = {44--60},
  issn = {0006-3495},
  doi = {10.1016/j.bpj.2021.12.006},
  urldate = {2023-05-16},
  abstract = {Cell dispersion from a confined area is fundamental in a number of biological processes, including cancer metastasis. To date, a quantitative understanding of the interplay of single-cell motility, cell proliferation, and intercellular contacts remains elusive. In particular, the role of E- and N-cadherin junctions, central components of intercellular contacts, is still controversial. Combining theoretical modeling with in~vitro observations, we investigate the collective spreading behavior of colonies of human cancer cells (T24). The spreading of these colonies is driven by stochastic single-cell migration with frequent transient cell-cell contacts. We find that inhibition of E- and N-cadherin junctions decreases colony spreading and average spreading velocities, without affecting the strength of correlations in spreading velocities of neighboring cells. Based on a biophysical simulation model for cell migration, we show that the behavioral changes upon disruption of these junctions can be explained by reduced repulsive excluded volume interactions between cells. This suggests that in cancer cell migration, cadherin-based intercellular contacts sharpen cell boundaries leading to repulsive rather than cohesive interactions between cells, thereby promoting efficient cell spreading during collective migration.},
  langid = {english},
  file = {/home/andonis/Zotero/storage/I5HYIJ4N/Zisis et al. - 2022 - Disentangling cadherin-mediated cell-cell interact.pdf;/home/andonis/Zotero/storage/DM9XMBK7/S0006349521038972.html}
}